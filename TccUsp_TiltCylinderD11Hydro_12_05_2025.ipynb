{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CidClayQuirino/rnn-component-lIfe-cycle/blob/main/TccUsp_TiltCylinderD11Hydro_12_05_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XANDzcvaAS3X"
      },
      "source": [
        "1) Juntar DataFrame\n",
        "=> Data\n",
        "=> Temperatura\n",
        "=> Vibração X\n",
        "=> Vibração Y\n",
        "=> Vibração Z\n",
        "\n",
        "2) Rodar RNN-LSTM\n",
        "=> Features Vibração x, y e z\n",
        "=> Target Temperatura\n",
        "\n",
        "3) Projetar resultado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "inaOBippAQyG"
      },
      "outputs": [],
      "source": [
        "!pip install markdown\n",
        "!pip install statsmodels\n",
        "!pip install scikit-learn\n",
        "!pip install PyGithub\n",
        "!pip install gitpython\n",
        "!pip install statsmodels\n",
        "!pip install dash\n",
        "!pip install xlwt\n",
        "!pip install openpyxl\n",
        "!pip install tensorflow\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDzhKQQ_BI-O"
      },
      "outputs": [],
      "source": [
        "# Atualizar pacotes\n",
        "from datetime import datetime\n",
        "from github import Github\n",
        "from io import BytesIO\n",
        "from scipy import stats\n",
        "from IPython.display import Image\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import L1L2\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "import warnings\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H5GdFI8J0mJ"
      },
      "source": [
        "***REMOÇÃO DOS OUTLIERS DO DATA FRAME BASE***\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "\n",
        "Q1 (Primeiro Quartil): É o valor que separa o primeiro quartil inferior (25%) dos restantes dados. Em outras palavras, 25% dos dados estão abaixo desse valor.\n",
        "\n",
        "IQR (Intervalo Interquartil): É a diferença entre o terceiro quartil (Q3) e o primeiro quartil (Q1). Representa a dispersão dos dados no intervalo onde a maioria dos dados está concentrada.\n",
        "\n",
        "Lower Bound (Limite Inferior): É calculado subtraindo 1,5 vezes o IQR do primeiro quartil (Q1). O objetivo é identificar outliers abaixo desse limite, considerando-os valores extremamente baixos em relação à dispersão dos dados.\n",
        "\n",
        "Portanto, lower_bound = Q1 - 1.5 * IQR é uma medida usada em análise de dados para identificar valores atípicos (outliers) abaixo do limite inferior, ajudando a detectar anomalias nos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H1VXBRfBJ-F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# URLs dos arquivos CSV no GitHub\n",
        "url_TE8039_LD = \"https://github.com/CidClayQuirino/rnn-component-lIfe-cycle/raw/main/TiltCylinderTE8039_LD.csv\"\n",
        "url_TE8039_LE = \"https://github.com/CidClayQuirino/rnn-component-lIfe-cycle/raw/main/TiltCylinderTE8039_LE.csv\"\n",
        "\n",
        "# Ler os arquivos CSV e criar DataFrames\n",
        "df_TE8039_LD = pd.read_csv(url_TE8039_LD)\n",
        "df_TE8039_LE = pd.read_csv(url_TE8039_LE)\n",
        "\n",
        "# Adicionar uma nova coluna \"NmeComp\" com o nome do arquivo\n",
        "df_TE8039_LD['NmeComp'] = 'TiltCylinderTE8039_LD'\n",
        "df_TE8039_LE['NmeComp'] = 'TiltCylinderTE8039_LE'\n",
        "\n",
        "# Concatenar os DataFrames\n",
        "df_tiltcylinder = pd.concat([df_TE8039_LD, df_TE8039_LE], ignore_index=True)\n",
        "\n",
        "# Converter a coluna \"Datetime\" para o tipo datetime\n",
        "df_tiltcylinder['Datetime'] = pd.to_datetime(df_tiltcylinder['Datetime'])\n",
        "\n",
        "# Extrair o dia e a hora\n",
        "df_tiltcylinder['Dia'] = df_tiltcylinder['Datetime'].dt.strftime('%Y-%m-%d')  # Formato 'YYYY-MM-DD'\n",
        "df_tiltcylinder['Hora'] = df_tiltcylinder['Datetime'].dt.strftime('%H:%M:%S')  # Formato 'HH:MM:SS'\n",
        "\n",
        "# Remover as colunas não desejadas\n",
        "df_tiltcylinder = df_tiltcylinder[['Temperatura', 'Velocidade X', 'Velocidade Y', 'Velocidade Z','NmeComp', 'Dia']]\n",
        "\n",
        "# Defina as colunas que você deseja considerar\n",
        "cols_of_interest = ['Temperatura', 'Velocidade X', 'Velocidade Y', 'Velocidade Z']\n",
        "\n",
        "# Calcule os quartis\n",
        "Q1 = df_tiltcylinder[cols_of_interest].quantile(0.25)\n",
        "Q3 = df_tiltcylinder[cols_of_interest].quantile(0.75)\n",
        "\n",
        "# Calcule o intervalo interquartil (IQR)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Defina o limite inferior (lower bound) para identificar outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "\n",
        "# Remova os outliers nas colunas de interesse\n",
        "for col in cols_of_interest:\n",
        "    df_tiltcylinder = df_tiltcylinder[(df_tiltcylinder[col] >= lower_bound[col]) | df_tiltcylinder[col].isna()]\n",
        "\n",
        "# Verifique se houve remoção de NaN e remova as linhas correspondentes\n",
        "df_tiltcylinder = df_tiltcylinder.dropna(subset=['NmeComp', 'Dia'])\n",
        "\n",
        "# Resetar o índice após a remoção dos outliers\n",
        "df_tiltcylinder = df_tiltcylinder.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4--bc2IZFvOm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suponha que você tenha um DataFrame chamado df_TE8039_LD\n",
        "# Remova as colunas 'Datetime' e 'NmeComp'\n",
        "df = df_tiltcylinder.drop(columns=['Dia', 'NmeComp'])\n",
        "\n",
        "# Use o método describe() para obter estatísticas descritivas, incluindo o máximo\n",
        "summary = df.describe()\n",
        "\n",
        "# Adicione os valores máximos ao resumo\n",
        "max_values = pd.DataFrame(df.max(), columns=['Max Value']).T\n",
        "summary = pd.concat([summary, max_values])\n",
        "\n",
        "# Verifique se o DataFrame tem valores iguais a zero\n",
        "has_zeros = pd.DataFrame((df == 0).any(), columns=['Has Zeros']).T\n",
        "\n",
        "# Adicione a nova linha ao summary\n",
        "summary = pd.concat([summary, has_zeros])\n",
        "\n",
        "# Exiba o summary\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcmXtePwMfaP"
      },
      "outputs": [],
      "source": [
        "df_TiltCylinderTE8039_LD = df_tiltcylinder.query(\"NmeComp == 'TiltCylinderTE8039_LD'\")\n",
        "df_TiltCylinderTE8039_LD.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy7F2HM3M4hS"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "\n",
        "# Encontrar os maiores valores em cada coluna\n",
        "max_temp = df[\"Temperatura\"].max()\n",
        "max_vx = df[\"Velocidade X\"].max()\n",
        "max_vy = df[\"Velocidade Y\"].max()\n",
        "max_vz = df[\"Velocidade Z\"].max()\n",
        "\n",
        "# Criar figura com subplots\n",
        "fig = make_subplots(rows=4, cols=1, subplot_titles=(\"Temperatura\", \"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"))\n",
        "\n",
        "# Adicionar histograma para cada coluna\n",
        "fig.add_trace(go.Histogram(x=df[\"Temperatura\"], name=\"Temperatura\"), row=1, col=1)\n",
        "fig.add_trace(go.Histogram(x=df[\"Velocidade X\"], name=\"Velocidade X\"), row=2, col=1)\n",
        "fig.add_trace(go.Histogram(x=df[\"Velocidade Y\"], name=\"Velocidade Y\"), row=3, col=1)\n",
        "fig.add_trace(go.Histogram(x=df[\"Velocidade Z\"], name=\"Velocidade Z\"), row=4, col=1)\n",
        "\n",
        "# Atualizar layout\n",
        "fig.update_layout(title=\"Histograma de Temperatura e Velocidades\",\n",
        "                  showlegend=True,\n",
        "                  height=800,  # Altura do gráfico\n",
        "                  width=1200,  # Largura do gráfico\n",
        "                  )\n",
        "\n",
        "# Ajustar os limites dos eixos\n",
        "fig.update_xaxes(range=[0, max_temp], row=1, col=1)\n",
        "fig.update_xaxes(range=[0, max_vx], row=2, col=1)\n",
        "fig.update_xaxes(range=[0, max_vy], row=3, col=1)\n",
        "fig.update_xaxes(range=[0, max_vz], row=4, col=1)\n",
        "\n",
        "# Exibir figura\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-SEPoBQZIJk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Selecionar uma amostra aleatória de 1000 pontos de dados\n",
        "df_sample = df_TiltCylinderTE8039_LD.sample(n=1000)\n",
        "\n",
        "# Criar figura com subplots\n",
        "fig = make_subplots(rows=2, cols=2, subplot_titles=(\"Temperatura\", \"Temperatura_Velocidade X\", \"Temperatura_Velocidade Y\", \"Temperatura_Velocidade Z\"))\n",
        "\n",
        "# Adicionar gráfico de dispersão para cada par de colunas\n",
        "fig.add_trace(go.Scatter(x=df_sample[\"Temperatura\"], y=df_sample[\"Velocidade X\"], mode='markers', name=\"Temperatura vs Velocidade X\"), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=df_sample[\"Temperatura\"], y=df_sample[\"Velocidade Y\"], mode='markers', name=\"Temperatura vs Velocidade Y\"), row=2, col=1)\n",
        "fig.add_trace(go.Scatter(x=df_sample[\"Temperatura\"], y=df_sample[\"Velocidade Z\"], mode='markers', name=\"Temperatura vs Velocidade Z\"), row=2, col=2)\n",
        "fig.add_trace(go.Scatter(x=df_sample[\"Velocidade X\"], y=df_sample[\"Velocidade Y\"], mode='markers', name=\"Velocidade X vs Velocidade Y\"), row=1, col=2)\n",
        "\n",
        "# Atualizar layout\n",
        "fig.update_layout(title=\"Gráfico de Dispersão entre Temperatura e Velocidades eixo X, Y e Z\",\n",
        "                  showlegend=True)\n",
        "\n",
        "# Exibir figura\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AX-aU37kpbQ"
      },
      "source": [
        "***LSTM***\n",
        "\n",
        "Rodar modelo LSNT para DF de dados Tilt Cylindro LD. e avaliar os resultados de MSE, MAE e R2 e gravar em um data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx9pbJBkanMZ",
        "outputId": "5aba3468-3a1d-4fd6-93cc-7c6c656ea2e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4405/4405 [==============================] - 52s 10ms/step - loss: 0.0511 - val_loss: 0.0506\n",
            "Epoch 2/10\n",
            "4405/4405 [==============================] - 29s 7ms/step - loss: 0.0503 - val_loss: 0.0506\n",
            "Epoch 3/10\n",
            "4405/4405 [==============================] - 30s 7ms/step - loss: 0.0503 - val_loss: 0.0504\n",
            "Epoch 4/10\n",
            "4405/4405 [==============================] - 29s 7ms/step - loss: 0.0502 - val_loss: 0.0502\n",
            "Epoch 5/10\n",
            "4405/4405 [==============================] - 30s 7ms/step - loss: 0.0503 - val_loss: 0.0503\n",
            "Epoch 6/10\n",
            "4405/4405 [==============================] - 31s 7ms/step - loss: 0.0502 - val_loss: 0.0506\n",
            "Epoch 7/10\n",
            "4405/4405 [==============================] - 31s 7ms/step - loss: 0.0503 - val_loss: 0.0504\n",
            "Epoch 8/10\n",
            "4405/4405 [==============================] - 28s 6ms/step - loss: 0.0503 - val_loss: 0.0503\n",
            "Epoch 9/10\n",
            "4405/4405 [==============================] - 28s 6ms/step - loss: 0.0502 - val_loss: 0.0503\n",
            "Epoch 10/10\n",
            "4405/4405 [==============================] - 28s 6ms/step - loss: 0.0503 - val_loss: 0.0503\n",
            "1101/1101 [==============================] - 4s 3ms/step\n",
            "Mean Squared Error (MSE): 164.54911340705317\n",
            "Mean Absolute Error (MAE): 9.883797255354287\n",
            "R^2 Score: -0.0012236745577964836\n",
            "  Modelo       MAE         MSE        R2\n",
            "0   LSTM  9.883797  164.549113 -0.001224\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l1_l2\n",
        "\n",
        "\n",
        "df_results_LSTM = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])\n",
        "\n",
        "# Carregar os dados\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "df = df.dropna()\n",
        "# Pré-processamento dos dados\n",
        "\n",
        "# Selecionar as features e o target\n",
        "X = df[[\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]].values\n",
        "y = df[\"Temperatura\"].values\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reformular os dados para o formato necessário para o modelo LSTM\n",
        "\n",
        "# Função para preparar os dados em samples\n",
        "def prepare_data(data, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)-time_steps):\n",
        "        X.append(data[i:i+time_steps, :])\n",
        "        y.append(data[i+time_steps, -1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Definir o número de time steps\n",
        "time_steps = 10  # Escolha o número adequado de time steps para o seu modelo\n",
        "\n",
        "# Reformular os dados\n",
        "X_train_samples, y_train_samples = prepare_data(np.column_stack((X_train, y_train)), time_steps)\n",
        "X_test_samples, y_test_samples = prepare_data(np.column_stack((X_test, y_test)), time_steps)\n",
        "\n",
        "# Construir e treinar o modelo LSTM\n",
        "\n",
        "# Definir os parâmetros do modelo\n",
        "lstm_units = 50\n",
        "dropout_rate = 0.2\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "loss = 'mean_squared_error'\n",
        "l1_reg = 0.001\n",
        "l2_reg = 0.001\n",
        "\n",
        "# Criar modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=lstm_units, input_shape=(X_train_samples.shape[1], X_train_samples.shape[2]),\n",
        "               kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compilar modelo\n",
        "model.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(X_train_samples, y_train_samples, epochs=10, batch_size=32, validation_data=(X_test_samples, y_test_samples))\n",
        "\n",
        "# Avaliar o modelo\n",
        "y_pred = model.predict(X_test_samples)\n",
        "\n",
        "# Inverter a normalização para obter os valores reais\n",
        "y_test_inverse = scaler_y.inverse_transform(y_test_samples.reshape(-1, 1)).flatten()\n",
        "y_pred_inverse = scaler_y.inverse_transform(y_pred).flatten()\n",
        "\n",
        "# Calcular métricas\n",
        "mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
        "mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
        "r2 = r2_score(y_test_inverse, y_pred_inverse)\n",
        "\n",
        "#Grava no DataFrame Resultado\n",
        "df_results_LSTM.loc[0] = ['LSTM', mae, mse, r2]\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "print(df_results_LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abTSXVcvk7Nr"
      },
      "source": [
        "***GRU***\n",
        "\n",
        "Rodar modelo GRU para DF de dados Tilt Cylindro LD. e avaliar os resultados de MSE, MAE e R2 e gravar em um data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We_Z8IVTizvl",
        "outputId": "b3ebae1d-60a0-4b4d-8ddd-7cf7613ae888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4405/4405 [==============================] - 32s 7ms/step - loss: 0.0509 - val_loss: 0.0501\n",
            "Epoch 2/10\n",
            "4405/4405 [==============================] - 29s 7ms/step - loss: 0.0501 - val_loss: 0.0501\n",
            "Epoch 3/10\n",
            "4405/4405 [==============================] - 30s 7ms/step - loss: 0.0501 - val_loss: 0.0510\n",
            "Epoch 4/10\n",
            "4405/4405 [==============================] - 31s 7ms/step - loss: 0.0501 - val_loss: 0.0519\n",
            "Epoch 5/10\n",
            "4405/4405 [==============================] - 30s 7ms/step - loss: 0.0501 - val_loss: 0.0500\n",
            "Epoch 6/10\n",
            "4405/4405 [==============================] - 31s 7ms/step - loss: 0.0500 - val_loss: 0.0506\n",
            "Epoch 7/10\n",
            "4405/4405 [==============================] - 29s 7ms/step - loss: 0.0501 - val_loss: 0.0501\n",
            "Epoch 8/10\n",
            "4405/4405 [==============================] - 29s 6ms/step - loss: 0.0501 - val_loss: 0.0502\n",
            "Epoch 9/10\n",
            "4405/4405 [==============================] - 29s 7ms/step - loss: 0.0501 - val_loss: 0.0502\n",
            "Epoch 10/10\n",
            "4405/4405 [==============================] - 30s 7ms/step - loss: 0.0500 - val_loss: 0.0500\n",
            "1101/1101 [==============================] - 3s 3ms/step\n",
            "Mean Squared Error (MSE): 164.34916611607935\n",
            "Mean Absolute Error (MAE): 10.01801442478632\n",
            "R^2 Score: -7.065381109727653e-06\n",
            "  Modelo        MAE         MSE        R2\n",
            "0    GRU  10.018014  164.349166 -0.000007\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l1_l2\n",
        "\n",
        "# Carregar os dados\n",
        "df_results_GRU = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])\n",
        "\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "df = df.dropna()\n",
        "\n",
        "# Pré-processamento dos dados\n",
        "# Selecionar as features e o target\n",
        "X = df[[\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]].values\n",
        "y = df[\"Temperatura\"].values\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reformular os dados para o formato necessário para o modelo GRU\n",
        "# Função para preparar os dados em samples\n",
        "def prepare_data(data, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)-time_steps):\n",
        "        X.append(data[i:i+time_steps, :])\n",
        "        y.append(data[i+time_steps, -1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Definir o número de time steps\n",
        "time_steps = 10  # Escolha o número adequado de time steps para o seu modelo\n",
        "\n",
        "# Reformular os dados\n",
        "X_train_samples, y_train_samples = prepare_data(np.column_stack((X_train, y_train)), time_steps)\n",
        "X_test_samples, y_test_samples = prepare_data(np.column_stack((X_test, y_test)), time_steps)\n",
        "\n",
        "# Construir e treinar o modelo GRU\n",
        "# Definir os parâmetros do modelo\n",
        "gru_units = 50\n",
        "dropout_rate = 0.2\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "loss = 'mean_squared_error'\n",
        "l1_reg = 0.001\n",
        "l2_reg = 0.001\n",
        "\n",
        "# Criar modelo GRU\n",
        "model = Sequential()\n",
        "model.add(GRU(units=gru_units, input_shape=(X_train_samples.shape[1], X_train_samples.shape[2]),\n",
        "               kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compilar modelo\n",
        "model.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(X_train_samples, y_train_samples, epochs=10, batch_size=32, validation_data=(X_test_samples, y_test_samples))\n",
        "\n",
        "# Avaliar o modelo\n",
        "y_pred = model.predict(X_test_samples)\n",
        "\n",
        "# Inverter a normalização para obter os valores reais\n",
        "y_test_inverse = scaler_y.inverse_transform(y_test_samples.reshape(-1, 1)).flatten()\n",
        "y_pred_inverse = scaler_y.inverse_transform(y_pred).flatten()\n",
        "\n",
        "# Calcular métricas\n",
        "mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
        "mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
        "r2 = r2_score(y_test_inverse, y_pred_inverse)\n",
        "\n",
        "# Grava no DataFrame Resultado\n",
        "df_results_GRU.loc[0] = ['GRU', mae, mse, r2]\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "print(df_results_GRU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFy-KHKYk-9K"
      },
      "source": [
        "***SVR***\n",
        "\n",
        "Rodar modelo SVR para DF de dados Tilt Cylindro LD. e avaliar os resultados de MSE, MAE e R2 e gravar em um data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZZ6qiEUjNf7",
        "outputId": "41a7e8df-9144-4928-ce63-8edcea55be3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 105.7422465514359\n",
            "Mean Absolute Error (MAE): 7.990059223823779\n",
            "R^2 Score: 0.3565032929396075\n",
            "  Modelo       MAE         MSE        R2\n",
            "0    SVR  7.990059  105.742247  0.356503\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Carregar os dados\n",
        "df_results_SVR = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])\n",
        "\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "df = df.dropna()\n",
        "\n",
        "# Pré-processamento dos dados\n",
        "# Selecionar as features e o target\n",
        "X = df[[\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]].values\n",
        "y = df[\"Temperatura\"].values\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Construir e treinar o modelo SVR\n",
        "\n",
        "# Criar modelo SVR\n",
        "model = SVR(kernel='rbf')  # Pode escolher diferentes tipos de kernel (rbf, linear, poly, etc.)\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Inverter a normalização para obter os valores reais\n",
        "y_test_inverse = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "y_pred_inverse = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Calcular métricas\n",
        "mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
        "mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
        "r2 = r2_score(y_test_inverse, y_pred_inverse)\n",
        "\n",
        "# Grava no DataFrame Resultado\n",
        "\n",
        "df_results_SVR.loc[0] = ['SVR', mae, mse, r2]\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "print(df_results_SVR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYulR-lJlG9_"
      },
      "source": [
        "Modelagem de Árvores de Decisão: Use modelos de árvores de decisão e suas extensões (como Random Forests) para identificar as features mais importantes na previsão do target. Isso pode ajudar a destacar quais features têm maior impacto na predição do target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw2JyqS2lPju",
        "outputId": "3ec2374c-af75-4082-f7a8-525c0abd4f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 212.57034539704475\n",
            "Mean Absolute Error (MAE): 10.843078197166905\n",
            "R^2 Score: -0.2936013915228384\n",
            "  Modelo        MAE         MSE        R2\n",
            "0    SVR  10.843078  212.570345 -0.293601\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "df_results_RandonForest = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])\n",
        "# Carregar os dados\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "df = df.dropna()\n",
        "\n",
        "# Selecionar as features e o target\n",
        "X = df[[\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]]\n",
        "y = df[\"Temperatura\"]\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Construir e treinar o modelo de Árvore de Decisão\n",
        "\n",
        "# Criar modelo de Árvore de Decisão\n",
        "model = DecisionTreeRegressor()\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Avaliar o modelo\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "df_results_RandonForest.loc[0] = ['SVR', mae, mse, r2]\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "print(df_results_RandonForest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "NTBDvd6w4Tpa",
        "outputId": "b142bc5f-8f03-498b-9e0e-298589b9d910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Modelo        MAE         MSE        R2\n",
            "0    SVR  10.843078  212.570345 -0.293601\n",
            "1    SVR   7.990059  105.742247  0.356503\n",
            "2    GRU  10.018014  164.349166 -0.000007\n",
            "3   LSTM   9.883797  164.549113 -0.001224\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Modelo        MAE         MSE        R2\n",
              "0    SVR  10.843078  212.570345 -0.293601\n",
              "1    SVR   7.990059  105.742247  0.356503\n",
              "2    GRU  10.018014  164.349166 -0.000007\n",
              "3   LSTM   9.883797  164.549113 -0.001224"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ac07117-2bd3-4979-aede-15af201c1b98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVR</td>\n",
              "      <td>10.843078</td>\n",
              "      <td>212.570345</td>\n",
              "      <td>-0.293601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVR</td>\n",
              "      <td>7.990059</td>\n",
              "      <td>105.742247</td>\n",
              "      <td>0.356503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRU</td>\n",
              "      <td>10.018014</td>\n",
              "      <td>164.349166</td>\n",
              "      <td>-0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>9.883797</td>\n",
              "      <td>164.549113</td>\n",
              "      <td>-0.001224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ac07117-2bd3-4979-aede-15af201c1b98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ac07117-2bd3-4979-aede-15af201c1b98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ac07117-2bd3-4979-aede-15af201c1b98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-de62f37a-ab41-4e7c-adc0-92c14f40a524\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de62f37a-ab41-4e7c-adc0-92c14f40a524')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-de62f37a-ab41-4e7c-adc0-92c14f40a524 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_resultsTiltClinderHydro",
              "summary": "{\n  \"name\": \"df_resultsTiltClinderHydro\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SVR\",\n          \"GRU\",\n          \"LSTM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2061484048346507,\n        \"min\": 7.990059223823779,\n        \"max\": 10.843078197166905,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          7.990059223823779,\n          9.883797255354287,\n          10.843078197166905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.719391335730364,\n        \"min\": 105.7422465514359,\n        \"max\": 212.57034539704475,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          105.7422465514359,\n          164.54911340705317,\n          212.57034539704475\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26604951880603384,\n        \"min\": -0.2936013915228384,\n        \"max\": 0.3565032929396075,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3565032929396075,\n          -0.0012236745577964836,\n          -0.2936013915228384\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# DataFrames contendo os resultados de diferentes modelos\n",
        "df_resultsTiltClinderHydro = pd.concat([df_results_RandonForest,\n",
        "                        df_results_SVR,\n",
        "                        df_results_GRU,\n",
        "                        df_results_LSTM], ignore_index=True)\n",
        "# Exibir o DataFrame resultante\n",
        "print(df_resultsTiltClinderHydro)\n",
        "df_resultsTiltClinderHydro.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6th0vVdZ5YKY",
        "outputId": "bd92b448-c39f-4b2a-8dc4-95b85756ab87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_resultsTiltClinderHydro.csv atualizado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Defina suas credenciais do GitHub\n",
        "seu_token = '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'\n",
        "seu_usuario = 'CidClayQuirino'\n",
        "seu_repositorio = 'rnn-component-lIfe-cycle'\n",
        "\n",
        "# Dicionário de DataFrames com seus nomes originais\n",
        "dataframes = {\n",
        "    'df_resultsTiltClinderHydro': df_resultsTiltClinderHydro}\n",
        "\n",
        "# Função para salvar e enviar para o GitHub\n",
        "def salvar_e_enviar_para_github(dataframe, nome_arquivo, usuario, repositorio, token):\n",
        "    # Salvar DataFrame como CSV em um BytesIO\n",
        "    csv_bytes = BytesIO()\n",
        "    dataframe.to_csv(csv_bytes, index=False)\n",
        "\n",
        "    # Autenticar no GitHub\n",
        "    g = Github(token)\n",
        "\n",
        "    # Obter o repositório\n",
        "    repo = g.get_user(usuario).get_repo(repositorio)\n",
        "\n",
        "    # Criar ou atualizar o arquivo no repositório\n",
        "    try:\n",
        "        arquivo = repo.get_contents(nome_arquivo)\n",
        "        repo.update_file(nome_arquivo, f'Atualizando {nome_arquivo}', csv_bytes.getvalue(), arquivo.sha)\n",
        "        print(f'{nome_arquivo} atualizado com sucesso!')\n",
        "    except Exception as e:\n",
        "        repo.create_file(nome_arquivo, f'Adicionando {nome_arquivo}', csv_bytes.getvalue())\n",
        "        print(f'{nome_arquivo} criado com sucesso!')\n",
        "\n",
        "# Iterar sobre os DataFrames e salvá-los no GitHub\n",
        "for nome, df in dataframes.items():\n",
        "    nome_arquivo = f'{nome}.csv'  # Nome do arquivo usando o nome original do DataFrame\n",
        "    salvar_e_enviar_para_github(df, nome_arquivo, seu_usuario, seu_repositorio, seu_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uns9tYL0miyl"
      },
      "source": [
        "O teste de causalidade de Granger é uma técnica estatística usada para determinar se uma série temporal pode prever outra série temporal. Em outras palavras, ele verifica se uma série temporal é \"causal\" para outra. Por exemplo, se uma série temporal X pode ser usada para prever uma série temporal Y, dizemos que X \"causa\" Y.\n",
        "\n",
        "O teste de causalidade de Granger é baseado na ideia de que se uma série temporal X pode prever outra série temporal Y, então as informações contidas em X devem ajudar a prever Y melhor do que se tivéssemos apenas as informações históricas de Y.\n",
        "\n",
        "Aqui está um resumo do processo do teste de causalidade de Granger:\n",
        "=>Formulação das hipóteses: As hipóteses nula e alternativa são definidas da seguinte forma:\n",
        "=>Hipótese nula (H0): A série temporal X não Granger-causa a série temporal Y.\n",
        "=>Hipótese alternativa (H1): A série temporal X Granger-causa a série temporal Y.\n",
        "=>Preparação dos dados: Os dados são divididos em dois conjuntos: um conjunto de treinamento e um conjunto de teste. O conjunto de treinamento é usado para ajustar os modelos, enquanto o conjunto de teste é usado para avaliar o desempenho do modelo.\n",
        "=>Ajuste do modelo: Modelos autoregressivos (AR) são ajustados para cada série temporal separadamente, usando a série temporal atual e suas defasagens como variáveis independentes.\n",
        "=>Teste estatístico: Um teste estatístico, geralmente baseado na estatística F ou no critério de informação Akaike (AIC), é realizado para determinar se a inclusão das defasagens da série temporal X melhora significativamente a previsão da série temporal Y.\n",
        "=>Interpretação do resultado: Se o valor p do teste for menor que um nível de significância predefinido (geralmente 0,05), rejeitamos a hipótese nula e concluímos que a série temporal X Granger-causa a série temporal Y.\n",
        "\n",
        "Em resumo, o teste de causalidade de Granger é uma ferramenta estatística útil para investigar relações de causalidade entre séries temporais. Ele é comumente usado em economia, finanças, ciências sociais e outras áreas onde análise de séries temporais é aplicada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr21DgTtm-7o",
        "outputId": "edbd26ca-a746-4080-ac8c-316e4f24e7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Teste de causalidade de Granger entre Velocidade X e Temperatura:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/stattools.py:1545: FutureWarning:\n",
            "\n",
            "verbose is deprecated since functions should not print results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lag 1: p-value = 0.0\n",
            "Lag 2: p-value = 0.0\n",
            "Lag 3: p-value = 0.0\n",
            "Lag 4: p-value = 0.0\n",
            "Lag 5: p-value = 0.0\n",
            "\n",
            "Teste de causalidade de Granger entre Velocidade Y e Temperatura:\n",
            "Lag 1: p-value = 0.0\n",
            "Lag 2: p-value = 0.0\n",
            "Lag 3: p-value = 0.0\n",
            "Lag 4: p-value = 0.0\n",
            "Lag 5: p-value = 0.0\n",
            "\n",
            "Teste de causalidade de Granger entre Velocidade Z e Temperatura:\n",
            "Lag 1: p-value = 0.0\n",
            "Lag 2: p-value = 0.0\n",
            "Lag 3: p-value = 0.0\n",
            "Lag 4: p-value = 0.0\n",
            "Lag 5: p-value = 0.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import grangercausalitytests\n",
        "\n",
        "# Carregar os dados\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "df = df.dropna()\n",
        "\n",
        "# Selecionar as features e o target\n",
        "X = df[[\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]]\n",
        "y = df[\"Temperatura\"]\n",
        "\n",
        "# Teste de causalidade de Granger\n",
        "# Você pode ajustar o lag máximo conforme necessário\n",
        "max_lag = 5  # Escolha o lag máximo a ser testado\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "\n",
        "for feature in X.columns:\n",
        "    print(f'\\nTeste de causalidade de Granger entre {feature} e Temperatura:')\n",
        "    data = pd.concat([X[feature], y], axis=1)\n",
        "    result = grangercausalitytests(data, max_lag, verbose=False)\n",
        "    for lag in range(1, max_lag+1):\n",
        "        p_value = result[lag][0][\"ssr_ftest\"][1]\n",
        "        results.append({\"Feature\": feature, \"Lag\": lag, \"p-value\": p_value})\n",
        "        print(f'Lag {lag}: p-value = {p_value}')\n",
        "\n",
        "# Converter a lista de resultados em DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Salvar os resultados em um arquivo CSV\n",
        "results_df.to_csv(\"resultados_granger.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BULZCt_Uw98f",
        "outputId": "a1478b68-8bb2-49df-9b84-07f9546a4f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Teste ADF para a coluna Velocidade X:\n",
            "Test Statistic: -25.195175424703326\n",
            "p-value: 0.0\n",
            "Critical Values:\n",
            "   1%: -3.430387135610472\n",
            "   5%: -2.861556413436186\n",
            "   10%: -2.566778736284117\n",
            "\n",
            "Teste ADF para a coluna Velocidade Y:\n",
            "Test Statistic: -25.36326189567145\n",
            "p-value: 0.0\n",
            "Critical Values:\n",
            "   1%: -3.430387134766943\n",
            "   5%: -2.8615564130633597\n",
            "   10%: -2.566778736085675\n",
            "\n",
            "Teste ADF para a coluna Velocidade Z:\n",
            "Test Statistic: -25.389898258413787\n",
            "p-value: 0.0\n",
            "Critical Values:\n",
            "   1%: -3.4303871341343215\n",
            "   5%: -2.8615564127837514\n",
            "   10%: -2.566778735936849\n",
            "\n",
            "Teste ADF para a coluna Temperatura:\n",
            "Test Statistic: -12.13963786560878\n",
            "p-value: 1.662437276727945e-22\n",
            "Critical Values:\n",
            "   1%: -3.43038713308\n",
            "   5%: -2.861556412317759\n",
            "   10%: -2.566778735688817\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Carregar os dados\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "\n",
        "# Remover linhas com valores ausentes, se necessário\n",
        "df = df.dropna()\n",
        "\n",
        "# Selecionar as colunas de interesse\n",
        "colunas = [\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\", \"Temperatura\"]\n",
        "\n",
        "# Realizar o teste ADF para cada coluna\n",
        "resultados_adf = {}\n",
        "\n",
        "for coluna in colunas:\n",
        "    print(f'\\nTeste ADF para a coluna {coluna}:')\n",
        "    resultado = adfuller(df[coluna])\n",
        "    resultados_adf[coluna] = {\"Test Statistic\": resultado[0], \"p-value\": resultado[1],\n",
        "                              \"Critical Values\": resultado[4]}\n",
        "    print(f'Test Statistic: {resultado[0]}')\n",
        "    print(f'p-value: {resultado[1]}')\n",
        "    print('Critical Values:')\n",
        "    for key, value in resultado[4].items():\n",
        "        print(f'   {key}: {value}')\n",
        "\n",
        "# Converter os resultados em DataFrame\n",
        "resultados_adf_df = pd.DataFrame(resultados_adf)\n",
        "\n",
        "# Salvar os resultados em um arquivo CSV\n",
        "resultados_adf_df.to_csv(\"resultados_adf.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YYPMDhRyDyp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Carregar os dados\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "\n",
        "# Remover linhas com valores ausentes, se necessário\n",
        "df = df.dropna()\n",
        "\n",
        "# Selecionar as colunas de interesse\n",
        "colunas = [\"Temperatura\", \"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]\n",
        "\n",
        "# Realizar o teste ADF para cada coluna\n",
        "resultados_adf = {}\n",
        "\n",
        "for coluna in colunas:\n",
        "    resultado = adfuller(df[coluna])\n",
        "    resultados_adf[coluna] = resultado[0]\n",
        "\n",
        "# Converter os resultados em DataFrame\n",
        "resultados_adf_df = pd.DataFrame.from_dict(resultados_adf, orient='index', columns=['Test Statistic'])\n",
        "\n",
        "# Plotar os resultados\n",
        "plt.figure(figsize=(10, 6))\n",
        "resultados_adf_df.plot(kind='bar', color='skyblue', alpha=0.7)\n",
        "plt.title('Teste ADF para cada coluna')\n",
        "plt.xlabel('Coluna')\n",
        "plt.ylabel('Test Statistic')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfGM_tNS1t07"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Carregar os dados\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "\n",
        "# Remover linhas com valores ausentes, se necessário\n",
        "df = df.dropna()\n",
        "\n",
        "# Selecionar as colunas de interesse e converter a coluna \"Data\" para datetime\n",
        "colunas = [\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\", \"Temperatura\"]\n",
        "df['Dia'] = pd.to_datetime(df['Dia'])\n",
        "\n",
        "# Criar figuras subplotadas\n",
        "fig = make_subplots(rows=len(colunas), cols=1, subplot_titles=colunas)\n",
        "\n",
        "# Adicionar traces para cada coluna\n",
        "for i, coluna in enumerate(colunas, start=1):\n",
        "    trace = go.Scatter(x=df['Dia'], y=df[coluna], mode='lines', name=coluna)\n",
        "    fig.add_trace(trace, row=i, col=1)\n",
        "\n",
        "# Atualizar layout\n",
        "fig.update_layout(title=\"Variação ao longo do tempo\",\n",
        "                  xaxis=dict(title='Dia'),\n",
        "                  yaxis=dict(title='Valor'),\n",
        "                  width=1200,  # largura do gráfico\n",
        "                  height=800)  # altura do gráfico\n",
        "\n",
        "# Exibir o gráfico interativo\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDpS05Qr3Fou"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Carregar os dados\n",
        "# Substitua \"seu_arquivo.csv\" pelo caminho do seu arquivo\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "\n",
        "# Remover linhas com valores ausentes, se necessário\n",
        "df = df.dropna()\n",
        "\n",
        "# Selecionar as colunas de interesse e converter a coluna \"Data\" para datetime\n",
        "colunas = [\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\", \"Temperatura\"]\n",
        "df['Dia'] = pd.to_datetime(df['Dia'])\n",
        "\n",
        "# Criar figuras subplotadas\n",
        "fig = make_subplots(rows=len(colunas), cols=1, subplot_titles=colunas)\n",
        "\n",
        "# Adicionar traces para cada coluna\n",
        "for i, coluna in enumerate(colunas, start=1):\n",
        "    trace = go.Bar(x=df['Dia'], y=df[coluna], name=coluna)\n",
        "    fig.add_trace(trace, row=i, col=1)\n",
        "\n",
        "# Atualizar layout\n",
        "fig.update_layout(title=\"Variação ao longo do tempo\",\n",
        "                  xaxis=dict(title='Dia'),\n",
        "                  yaxis=dict(title='Valor'),\n",
        "                  width=1200,  # largura do gráfico\n",
        "                  height=800)  # altura do gráfico\n",
        "\n",
        "# Exibir o gráfico interativo\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQyo4TgvCjtE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Suponha que 'df' seja o nome do seu dataframe com as colunas \"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\" e \"Temperatura\"\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "\n",
        "# Remover linhas com valores ausentes, se necessário\n",
        "df = df.dropna()\n",
        "\n",
        "# Dividir os dados em features (X) e target (y)\n",
        "X = df[[\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]]\n",
        "y = df[\"Temperatura\"]\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criar o modelo de árvore de decisão\n",
        "modelo_arvore = DecisionTreeRegressor()\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo_arvore.fit(X_train, y_train)\n",
        "\n",
        "# Exibir a árvore de decisão\n",
        "tree_rules = export_text(modelo_arvore, feature_names=list(X.columns))\n",
        "print(tree_rules)\n",
        "\n",
        "# Plotar a árvore de decisão (opcional)\n",
        "from sklearn.tree import plot_tree\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(modelo_arvore, feature_names=list(X.columns), filled=True, fontsize=10)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fyj1tVjCR0pq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Suponha que 'df' seja o nome do seu dataframe com as colunas \"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\" e \"Temperatura\"\n",
        "df = df_TiltCylinderTE8039_LD\n",
        "\n",
        "# Remover linhas com valores ausentes, se necessário\n",
        "df = df.dropna()\n",
        "\n",
        "# Dividir os dados em features (X) e target (y)\n",
        "X = df[[\"Velocidade X\", \"Velocidade Y\", \"Velocidade Z\"]]\n",
        "y = df[\"Temperatura\"]\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criar o modelo de árvore de decisão\n",
        "modelo_arvore = DecisionTreeRegressor()\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo_arvore.fit(X_train, y_train)\n",
        "\n",
        "# Plotar a árvore de decisão\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(modelo_arvore, feature_names=X.columns, filled=True, fontsize=10)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKo1bdv5jtwg1Iq7xs7I4T",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}