# rnn-component-lIfe-cycle
Neural Network to project component life cycle for minor component on mining mobile equipments

**1.	T√≠tulo do projeto**

__Otimiza√ß√£o da condi√ß√£o de equipamentos de minera√ß√£o, usando manuten√ß√£o preditiva e IoT com Aprendizado de m√°quina.__

**2.	Introdu√ß√£o**

Nos √∫ltimos anos, diversos s√£o os artigos e estudos demonstrando os avan√ßos no monitoramento de equipamentos industriais, tendo como objetivos a redu√ß√£o a utiliza√ß√£o de seres humanos devido aos riscos inerentes, dificuldade de acesso aos locais de execu√ß√£o alem da redu√ß√£o na parada dos equipamentos com a antecipa√ß√£o de falhas, Tian, Y. M. et al. (1992) aponta que por outro lado, a produtividade e utiliza√ß√£o dos equipamentos mec√¢nicos continua a aumentar, ou seja, a efici√™ncia e produ√ß√£o com o aumento no n√≠vel de automa√ß√£o est√£o cada vez mais elevados, colaborando ainda mais com a necessidade de melhorar o monitoramento da sa√∫de dos ativos.  

Acrescenta-se a isso a avalia√ß√£o de que, os equipamentos industriais apresentam dificuldades mesmo com o avan√ßo nas t√©cnicas de automatiza√ß√£o, como relatado por Schmidt and Berns (2013) , apontando o fato de a manuten√ß√£o e inspe√ß√£o de grandes estruturas com sistemas aut√¥nomos ainda √© um problema sem solu√ß√£o, eles avaliaram que existem diversas poss√≠veis abordagem com a utiliza√ß√£o de rob√¥s para automatizar as inspe√ß√µes aumentar a qualidade e confiabilidade, contudo ainda existe muito espa√ßo para avan√ßo nestas t√©cnicas em v√°rias √°reas.  

Para Park C. et al (2016), a manuten√ß√£o preditiva atrai mais interesse do que a manuten√ß√£o de rotina, que √© descrita como sendo a manuten√ß√£o realizada quando ocorre uma falha na m√°quina. Eles atribuem isso ao fato de que as t√©cnicas de manuten√ß√£o preditiva ajudam a determinar a condi√ß√£o dos equipamentos ou sistemas em servi√ßo, e possibilitam avaliar e prever quando a manuten√ß√£o deve ser realizada. A manuten√ß√£o preditiva permite o agendamento conveniente de a√ß√µes corretivas e evita paradas inesperadas do equipamento, sendo que a chave √© a informa√ß√£o certa no momento certo.   

Ao saber quais equipamentos ou componentes precisam de manuten√ß√£o, os respons√°veis pelo departamento de manuten√ß√£o podem antecipar as manuten√ß√µes, e o que seriam paradas n√£o planejadas, podem ser transformadas em paradas mais curtas e mais eficientes, aumentando assim a disponibilidade do equipamento. Esta abordagem geralmente utiliza t√©cnicas estat√≠sticas de controle de processos, para determinar em que ponto as futuras atividades de manuten√ß√£o ser√£o apropriadas. Para avaliar a condi√ß√£o do equipamento, a manuten√ß√£o preditiva utiliza testes n√£o destrutivos, sensoriamento e coleta de dados de par√¢metros tais como temperatura e vibra√ß√£o, an√°lise de n√≠vel sonoro e outros testes em tempo real.  

Al√©m disso, Gbadamosi et al (2021) observa que algumas abordagens atuais exigem o envio de inspetores para √°reas, para realizar verifica√ß√µes de rotina, o que representa riscos para a sa√∫de e a seguran√ßa dos trabalhadores, por outro lado, quando temos um monitoramento eficiente dos ativos com m√©todos inovadores de coleta online por exemplo, esse risco pode ser reduzido e at√© mesmo eliminado.  

Quanto aos ativos utilizados em aplica√ß√µes de minera√ß√£o, √© poss√≠vel identificar diferentes n√≠veis de monitoramento, visto que alguns sistemas e componentes possuem maior cobertura por sensoriamento, tais como os componentes principais: Motores de combust√£o interna, Transmiss√£o, Pneus e Comandos Finais, j√° os componentes menores, como cilindros, bombas e motores hidr√°ulicos, s√£o poucos os pontos de monitoramento, e quando s√£o identificados, a captura dos dados e o monitoramento √© realizado de maneira indireta, como  exemplo podemos citar o monitoramento em alguns modelos de maquin√°rio, onde a temperatura dos componentes do sistema hidr√°ulicos que √© feita no tanque, utilizando este dado como sendo a temperatura do sistema e n√£o do componente em si, o que pode gerar retardo na tomada de decis√£o em caso de varia√ß√£o.   

Artur Skoczylas et al (2023) avalia que cada vez mais √© necess√°rio um sistema aprimorado que capture, gerencie e seja eficaz no apoio a decis√£o para o gestor da manuten√ß√£o, para isso √© fundamental que as empresas empenhem em ter ecossistemas com capacidade de centralizar os v√°rios aspectos importantes dos ativos moveis, a fim de garantir o monitoramento continuo do estado das m√°quinas de maneira mais ampla, a fim de prever avarias e planejar trabalhos de repara√ß√£o antecipadamente (Manuten√ß√£o Preditiva).  

Ferreira, B et al. (2022) aborda a demanda crescente por processos digitalizados a partir da evolu√ß√£o tecnol√≥gica na Ind√∫stria 4.0, a necessidade de acesso a dados de maneira mais r√°pida, intuitiva e barata, e indica pontos de desenvolvimento de solu√ß√µes vi√°veis e de baixo custo para auxiliar na visualiza√ß√£o de dados e na utiliza√ß√£o destes em antecipa√ß√£o de falhas.  

Artur Skoczylas et al. (2023) tamb√©m avalia que na maioria das grandes empresas, as m√°quinas foram equipadas com sistemas que medem diversos par√¢metros, como rota√ß√£o do motor, temperatura do √≥leo, press√£o do sistema hidr√°ulico, temperatura dos componentes mais importantes, press√£o dos pneus, consumo de combust√≠vel, velocidade de movimento etc. os sistemas podem enviar dados em tempo real, no entanto, isso n√£o √© praticado em grande escala no mercado, devido aos elevados custos operacionais dessa mudan√ßa.   

Este potencial de melhora no monitoramento para abranger tamb√©m os pequenos componentes, foi a oportunidade identificada neste estudo, que indica uma das possibilidades de avan√ßar sobre o processo de Gerenciamento de Monitoramento de Condi√ß√µes (CMMS) ampliando a cobertura para os pequenos componentes, com a aplica√ß√£o de sensores de temperatura e vibra√ß√£o, a fim de coletar par√¢metros e identificar mudan√ßas no comportamento desses par√¢metros ao longo de uma s√©rie temporal, com isso definir por uma interven√ß√£o antes da ocorr√™ncia de falhas.  


  - **2.1.	Objetivo**

A principal oportunidade identificada neste estudo, foi a necessidade de otimizar os atuais processos de Gerenciamento de Monitoramento de Condi√ß√µes (CMMS) para pequenos componentes, utilizando para tal, a aplica√ß√£o de sensores de temperatura e vibra√ß√£o, possibilitando com isso, a coleta em tempo real de par√¢metros ao longo de uma s√©rie temporal e identificar as varia√ß√µes nos padr√µes e definir por uma interven√ß√£o antes da ocorr√™ncia de falhas. 

Com base nessa oportunidade, foi elaborado um projeto de sensoriamento com Internet das Coisas (IoT), para pequenos componentes em uma escavadeira hidr√°ulica de minera√ß√£o e aplicado em campo em uma situa√ß√£o real de opera√ß√£o de mina de c√©u aberto.  

A justificativa deste estudo, est√° nas dificuldades identificadas nas m√°quinas moveis utilizadas em minera√ß√£o, de se obter par√¢metros preditivos para o monitoramento das condi√ß√µes em pequenos componentes, e com isso, melhorar a previsibilidade de interven√ß√£o antes das falhas. 

Logo, este estudo foca no desenvolvimento e aplica√ß√£o de alternativas vi√°veis para coleta, an√°lise de proje√ß√£o de sa√∫de em pequenos componentes, tendo como principal objetivo avan√ßar na manuten√ß√£o preditiva e na redu√ß√£o de falhas prematura, menor tempo de inatividade, atendendo tamb√©m os requisitos de seguran√ßa, com a menor exposi√ß√£o aos riscos humanos para a inspe√ß√£o.  

**3.	Material e M√©todos**

Para a an√°lise dos dados deste estudo, ser√° utilizada uma base de dados com 8226 observa√ß√µes de temperatura e vibra√ß√£o de ambas as bombas principais da 395, coletados no per√≠odo de 14 dias de opera√ß√£o como amostra, posteriormente, os dados estar√£o no PipeLine online, e ser√£o avaliados assim que forem coletados e disponibilizados.  

Os dados foram extra√≠dos em um formato .csv e importados do GitHub para o Python e bibliotecas a seguir:
  - NumPy: Biblioteca que fornece suporte para arrays multidimensionais, juntamente com a ampla cole√ß√£o de fun√ß√µes matem√°ticas para operar com an√°lise de dados, computa√ß√£o num√©rica.  
  - Satsmodels: Biblioteca Python que oferece classes e fun√ß√µes para estimar e interpretar diversos modelos estat√≠sticos, incluindo m√©todos para ajustar modelos de regress√£o, an√°lise de s√©ries temporais, testes estat√≠sticos etc.  
  - Scikit-learn: Biblioteca para aprendizado de m√°quina que fornece uma ampla variedade de algoritmos de aprendizado supervisionado e n√£o supervisionado. 
  - PyGithub: Biblioteca Python que fornece uma interface para interagir com a API do GitHub, facilitando a automatiza√ß√£o de tarefas como cria√ß√£o de reposit√≥rios.
  - TensorFlow: Biblioteca de c√≥digo aberto para aprendizado de m√°quina e intelig√™ncia artificial desenvolvida pelo Google, oferece uma estrutura tanto para construir quanto treinar modelos de aprendizado profundo, incluindo redes neurais convolucionais, redes neurais recorrentes e muito mais.

  - **3.1.	Manuten√ß√£o Preditiva, Preventiva e Corretiva**

A manuten√ß√£o corretiva pode ser descrita, segundo Nascimento et al. (2020) como sendo a modalidade de manuten√ß√£o aplicada ap√≥s a ocorr√™ncia da falha, com a finalidade de colocar o ativo em funcionamento novamente ou quando h√° pera da funcionalidade do equipamento e se pretende reestabelecer a opera√ß√£o. Essa modalidade pode ser dividida em dois tipos, corretiva planejada e n√£o planejada.  

J√° a manuten√ß√£o preventiva, tamb√©m de acordo com Nascimento et al. (2020) √© a modalidade de manuten√ß√£o aplicada com o intuito de diminuir a probabilidade de falha e manter o desempenho, √© desenvolvida atrav√©s de procedimentos, planos de manuten√ß√£o e inspe√ß√µes, executada   em   intervalos   regulares, ap√≥s os   quais   realiza-se   a substitui√ß√£o ou o reparo de itens em que foram detectadas anomalias, podendo citar como sendo as atividades de manuten√ß√£o preventiva.

Por √∫ltimo, e considerando sua import√¢ncia na Industria 4.0, temos a manuten√ß√£o preditiva, essa modalidade de manuten√ß√£o se utiliza de dados para as an√°lises em pontos espec√≠ficos do ativo, tais como, confer√™ncia de n√≠vel de √≥leo, an√°lise de vibra√ß√£o e an√°lise de temperatura, sendo comumente aplicada com a finalidade de monitorar o padr√£o de funcionamento do ativo e identificar potencial de falha quando existente.

Esta √∫ltima modalidade de manuten√ß√£o, a preditiva, se caracteriza pelo uso de instrumentos de medi√ß√£o e coleta massiva de dados como ferramenta de apoio a decis√£o de uma interven√ß√£o. Neste sentido, o uso de IoTs vem sendo amplamente usado pela ind√∫stria, para o avan√ßo das t√©cnicas de preditiva, e ser√° mais bem detalhado a seguir.

O Avan√ßo do uso de IoTs e seu avan√ßo na ind√∫stria 4.0, pode ser considerado a base deste estudo que visa otimizar a condi√ß√£o de equipamentos de minera√ß√£o, como apresentado no t√≥pico posterior, onde pode ser visto o uso da manuten√ß√£o preditiva e IoT como sendo a base para aumentar a coleta e disponibilidade de dados de m√°quina, e avan√ßar na atua√ß√£o preditiva.
 
Alexandre R. Oliveira (2023) cita essa problem√°tica em seu estudo, descrevendo de forma clara que as m√°quinas e equipamentos industriais n√£o foram constru√≠dos para durar para sempre contudo, podem durar muito mais. Ele acrescenta que os eventos de falhas de ativos s√£o processos de degrada√ß√£o, e que podem ser didaticamente apresentados por meio da curva P-F visto na figura 1, que busca representar a condi√ß√£o de um equipamento ou componente ao longo do tempo, dando claramente uma indica√ß√£o sobre o avan√ßo da condi√ß√£o x tempo, indicando a necessidade de agir proativamente para evitar a falha.

![Figura 1. Intervalo P-F. Fonte: Oliveira (2023).](G:/RNN_Sensor%20Dynamox/Git%20Reposit%C3%B3rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%201.%20Intervalo%20P-F.png)

Oliveira (2023) em seu estudo, tamb√©m aponta para utiliza√ß√£o de tecnologias no monitoramento do intervalo P-F como sendo uma estrat√©gia inteligente com maior assertividade e confiabilidade na manuten√ß√£o dos seus equipamentos e com isso a equipe de manuten√ß√£o pode evitar as quebras repentinas, e que as falhas identificadas entre os pontos P e F da curva, podem ser corrigidas evitando uma falha funcional com o uso de softwares, sensores e intelig√™ncia artificial realizando a coleta de dados das m√°quinas, para ter uma vis√£o completa dos processos industriais.


- **3.2.	Internet das coisas IoT**

Como citado por Aguirre (2021), a IoT pode ser considerado um mundo onde os objetos f√≠sicos s√£o perfeitamente √† rede de informa√ß√µes se tornando parte ativa dos fluxos e processos de neg√≥cios Haller et al. (2015), este √© um dos principais objetivos do estudo em quest√£o, pois substitui em boa medida, a necessidade de um inspetor ir at√© o ativo expondo-se ao risco para coleta de dados que podem ser facilmente, e constantemente coletadas pelos sensores.

Aguirre (2021) comenta que o surgimento da IoT de baixo custo promete acesso generalizado a sensores e dados que podem ser usados para a tomada de decis√µes operacionais. Em seu estudo uso as IoT, foi elaborado em um caso real onde foi aplicado um sistema para informar mudan√ßas na gest√£o operacional que resultaram na redu√ß√£o do tempo de carregamento, na Figura 2 ele apresenta uma sequ√™ncia esquem√°tica desde o dispositivo at√© a aplica√ß√£o em si, utilizada para avaliar o processo com a otimiza√ß√£o das rotas dos caminh√µes de minera√ß√£o e no controle da velocidade dos caminh√µes para maior seguran√ßa sem aumento no custo de minera√ß√£o.

![Figura 2: Device design and network.Fonte: H. Aguirre-Jofre et al (2021)](G:/RNN_Sensor_Dynamox/Git_Reposit√≥rio/rnn-component-life-cycle/rnn-component-life-cycle-main/VsCode/Figura_2_Device_design_and_network.png)
](G:/RNN_Sensor_Dynamox/Git_Reposit√≥rio/rnn-component-life-cycle/rnn-component-life-cycle-main/VsCode/Figura_2_Device_design_and_network.png)

O estudo aqui apresentado, tamb√©m faz uso de dispositivos de IoTs de custo significativamente baixos, com uma camada de an√°lise est√°tica e algoritmos que buscam otimizar o processo de an√°lise dos dados, usando de t√©cnicas de Machine Learning na identifica√ß√£o de varia√ß√µes nos padr√µes de comportamento consideradas an√¥malos, demonstrando o potencial do CMMS e da integra√ß√£o de tecnologias avan√ßadas para otimizar o monitoramento de condi√ß√µes em componentes cr√≠ticos de equipamentos de minera√ß√£o.

J.P. Dias et al. (2022) em seu artigo ‚ÄúProjetando e construindo sistemas de internet das coisas: um Vis√£o geral do ecossistema ‚Äú, contribui com uma vis√£o ampla e geral do atual estado da arte sobre como projetar e construir sistemas de IoT, e aponta com clareza os desafios de dessa √°rea.

Na figura 3 e mostrado o aumento do n√∫mero de dispositivos de IoT por ano, onde J.P. Dias et al. (2022) avaliam tanto o aumento consider√°vel de projetos de pesquisa quando a quantidade de dispositivos, demonstrando o interesse tanto da academia quando das empresas/pessoas por esta solu√ß√£o.


![Figura 3. Contagem do n√∫mero de dispositivos IoT por ano. Fonte: J.P. Dias et al.(2022)](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%203%20Contagem%20do%20n√∫mero%20de%20dispositivos%20IoT%20por%20ano.png)

J.P. Dias et al. (2022) relembram que o termo Internet das Coisas foi cunhado por Kevin Ashton por volta de 1999 em uma apresenta√ß√£o sobre o gerenciamento da cadeia de suprimentos, e que posteriormente o termo foi apresentado pelo comit√™ t√©cnico conjunto da International Organization for Standardization (ISO) e a Comiss√£o Eletrot√©cnica Internacional (IEC), definiram Internet das Coisas como sendo uma infraestrutura composta por objetos, pessoas, sistemas e recursos de informa√ß√£o todos interconectados, acrescenta-se a isso os servi√ßos inteligentes para permitir que eles processem informa√ß√µes sobre o mundo f√≠sico e virtual.

Este trabalho teve como ponto de partida, um estudo pr√©vio que obteve resultados promissores em termos de monitoramento preditivo, utilizando c√¢mera termogr√°fica, e ser√° explicado em detalhes a seguir neste estudo. Com base nesse trabalho anterior, avan√ßamos com este estudo, a fim de expandir o m√©todo, empregando mecanismos de Internet das Coisas (IoT) para obter dados diretamente dos componentes, possibilitando a an√°lise de dados para detectar altera√ß√µes de temperatura e vibra√ß√£o antes de uma falha catastr√≥fica.

A instala√ß√£o e configura√ß√£o dos sensores no equipamento foi realizada, considerando a cobertura de 100% dos pequenos componentes, que n√£o s√£o cobertos pelo monitoramento do fabricante, tal como descrito posteriormente nas Figuras 3, a seguir.

![Figuras 4a 4b 4c 4a 4d 4e 4f 4g 4h 4i. Instala√ß√£o dos dispositivos IoT Temperatura_Vibra√ß√£o nos componentes em campo. Fonte: Pr√≥prio Autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figuras%204a%204b%204c%204a%204d%204e%204f%204g%204h%204i.%20Instala√ß√£o%20dos%20dispositivos%20IoT%20Temperatura_Vibra√ß√£o%20nos%20componentes%20em%20campo.png)

Estes s√£o sensores que coleta e enviam para um reposit√≥rio na nuvem, os dados de temperatura e vibra√ß√£o dos componentes, o detalhamento deste fluxo e a configura√ß√£o est√£o mais bem descritos nos t√≥picos posteriores de 3.3. e 3.7, onde ser√° descrito com detalhes a aplica√ß√£o, coleta e tratamento dos dados.

  - **3.3.	Armazenamento na Nuvem**

Neste estudo, considerando os desafios de implementa√ß√£o e o foco na implementa√ß√£o de solu√ß√µes mais focado na camada de Data Science, foi definido pelo uso de um sensor que coleta temperatura e vibra√ß√£o e que j√° possui, todo o ecossistema de IoT desenvolvido, eliminando assim a necessidade de estabelece e implementar estes pontos, e permitindo avan√ßar diretamente para a parte de An√°lise estat√≠stica dos Dados ap√≥s estarem disponibilizados na Nuvem. Ou seja, existe boas op√ß√µes de solu√ß√µes compat√≠veis e dispon√≠veis no mercado para coletar e disponibilizar os dados, sendo algumas de custo mais elevado, outras com mais facilidade de instala√ß√£o e menor complexidade do possibilitando que o foco desse trabalho fosse direcionado para a an√°lise e proje√ß√£o dos dados ap√≥s estarem dispon√≠veis. Na Figura 5 tem uma estrutura b√°sica de camadas de IoTs desde a coleta dos dados, armazenamento e posterior an√°lise dos dados utilizando neste caso, a nuvem.

Como apontado tamb√©m por J.P. Dias et al. (2022), existem pontos cr√≠ticos nesta etapa do processo, ligados a heterogeneidade, distribui√ß√£o l√≥gica e geogr√°fica, preocupa√ß√µes humanas, necessidades de comunica√ß√£o em tempo real e restri√ß√µes de energia desempenham um papel fundamental no projeto, desenvolvimento, testes e manuten√ß√£o da IoT.

![Figura 5. Vis√£o logica de uma Camada comum de Sistema IoT](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%205.%20Vis√£o%20logica%20de%20uma%20Camada%20comum%20de%20Sistema%20IoT.png)

Com isso, definimos pela solu√ß√£o integrada da empresa nacional Dynamox, adquirimos os sensores para instala√ß√£o em campo + o Gateway, possibilitando o foco de nosso estudo na camada de ETL dos dados. 

O Sistema DynaPredict, coleta e disponibiliza em tempo real todos os dados via API da base da empresa no Google Could para nossa base na nuvem, tamb√©m no Google Cloud, conforme apresentado na Figura 4. Posteriormente foi desenvolvida todo tratamento e an√°lise dos dados de Temperatura e Vibra√ß√£o conforme ser√° detalhado a seguir neste estudo, tendo como principal foco, as Bombas Principais da escavadeira Caterpillar modelo 395.

A estrutura da Figura 6, j√° est√° predisposta para receber os dados de campo de cada um dos sensores de forma online, via o Gateway utilizando sistema GSN 2, 3 ou 4g.

![Figura 6. Vis√£o Arvore de componentes Nuvem de Dados. Fonte: Pr√≥prio Autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%206.%20Vis√£o%20Arvore%20de%20componentes%20Nuvem%20de%20Dados.jpg)


  - **3.4.	Series temporais**

Aliene Nielsen (2021) descreve uma hist√≥ria sobre a import√¢ncia das series temporais em nosso dia a dia, e correlaciona isso a evolu√ß√£o das IoTs, salientando a relev√¢ncia e import√¢ncia deles em nosso cotidiano, ele ressalta aumento exponencial do uso das series temporais inicialmente na medicina como tendo o pioneirismo na gera√ß√£o de dados, meteorologia e crescimento econ√¥mico vindo posteriormente bem como o mercado de trading e astronomia.

Anderson et al. (2023) avalia uma s√©rie temporal como sendo um conjunto de vari√°veis ordenadas em fun√ß√£o do tempo, e que o estudo e modelagem destes dados, √© fundamental para compreender o comportamento e realizar previs√µes sobre determinados dados. Ele orienta para a necessidade de realiza√ß√£o de um estudo do tipo de serie temporal que est√° sendo objeto de an√°lise e proje√ß√£o, e que em caso de observar que os dados possuem tend√™ncia estoc√°stica, √© preciso avaliar pois isso pode tornar as previs√µes imprecisas conforme se afastam do √∫ltimo ponto da amostra. Para tanto, ele orienta a utiliza√ß√£o do procedimento para a avalia√ß√£o da estacionariedade da s√©rie, por meio do teste de Dickey-Fuller, como sendo um dos testes de raiz unit√°ria mais tradicionais. A seguir, temos na Eq (1, 2 e 3) representando o teste de Dickey-Fuller.

y_t=‚àÖy_(t-1)+u_t                                                                                                                                   (1)

y_t=Œ≤_1+‚àÖy_(t-1)+ u_t                                                                                                                              (2)

y_t=Œ≤_1+Œ≤_2 t+ ‚àÖy_(t-1)+ u_t                                                                                                                       (3)


em que ùúô √© um par√¢metro a ser estimado, ùë¢ùë° √© um processo de ru√≠do branco, que se caracteriza como uma sequ√™ncia de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (iid), com m√©dia zero e vari√¢ncia constante (ùë¢ùë°‚àºùëÖùêµ (0, ùúé2)), ùõΩ1√© uma constante que representa o intercepto e ùõΩ2 √© um efeito de tend√™ncia. O teste considera como hip√≥tese nula, ùêª0 ‚à∂ ùúô= 1, a presen√ßa de raiz unit√°ria e como hip√≥tese alternativa, ùêª1‚à∂ùúô <|1|, a s√©rie sendo estacion√°ria.

Silveira et al. (2022) Na presen√ßa de estacionariedade, a fun√ß√£o amostral que descreve o processo gerador dos da dos tem a mesma forma em todos os instantes, facilitando a identifica√ß√£o de estimativas dos par√¢metros desconhecidos dos modelos especificados, e relaciona alguns avan√ßos nos testes de ADF e sugere a utiliza√ß√£o do c√°lculo do valor- p como determinado a partir da estat√≠stica œÑ no teste ADF, e poss√≠veis interfer√™ncias no resultado.
	
Em nosso estudo, definiremos o valor-p (p-value) e em caso de valores pr√≥ximo de zero, indica que h√° forte evid√™ncia estat√≠stica contra a hip√≥tese nula de que a s√©rie temporal √© n√£o estacion√°ria, ou seja, √© poss√≠vel concluir com confian√ßa que a s√©rie temporal √© estacion√°ria. 
	
Aileen Nielsen (2021) explica, que se a s√©rie temporal √© estacion√°ria simplifica significativamente a an√°lise e modelagem pois indica que suas propriedades estat√≠sticas, como m√©dia, vari√¢ncia e autocorrela√ß√£o, permanecem constantes ao longo do tempo. Isso permite aplicar uma variedade de t√©cnicas de modelagem e previs√£o com mais confian√ßa.
	
Aliene Nielsen (2021) separa os modelos estat√≠sticos de series temporais entre, est√°ticos, modelos de esparo de estado e aprendizado de m√°quina, sendo que em nosso estudo, utilizaremos alguns destes descritos a seguir, sendo que a avalia√ß√£o e defini√ß√£o do modelo mais aderente estar√° condicionada aos resultados de MAE (), MSE e R2 para os seguintes modelos, conforme descrito por Aur√©lien G√©ron (2021) como sendo alguns dos m√©todos estat√≠sticos desenvolvidos para series temporais:

Regress√£o Linear Simples ou M√∫ltipla: Aur√©lien G√©ron (2021) A regress√£o linear √© um modelo simples que pode ser eficaz se houver uma rela√ß√£o linear direta entre as vari√°veis de entrada e sa√≠da.

Modelos Autorregressivos (AR): Modelos autorregressivos consideram a rela√ß√£o entre uma observa√ß√£o atual e observa√ß√µes passadas. Eles s√£o √∫teis quando h√° depend√™ncia temporal nas s√©ries temporais.

M√©dias M√≥veis (MA): Modelos de m√©dias m√≥veis consideram a rela√ß√£o entre uma observa√ß√£o e um erro residual das observa√ß√µes passadas. Eles podem ser combinados com modelos AR para formar modelos ARMA.

Modelos ARIMA (Autoregressive Integrated Moving Average): Aur√©lien G√©ron (2021) avalia que os modelos ARIMA combinam componentes de regress√£o autorregressiva, m√©dias m√≥veis e diferencia√ß√£o para modelar s√©ries temporais estacion√°rias ou com tend√™ncias conhecidas.

Suaviza√ß√£o Exponencial (Exponential Smoothing): Modelos recomendados para suavizar s√©ries temporais e capturar padr√µes sazonais.

Redes Neurais Recorrentes (RNNs): Como dito por Aur√©lien G√©ron (2021), modelos de redes neurais recorrentes, como LSTM e GRU, s√£o eficazes para capturar depend√™ncias de longo prazo em s√©ries temporais, sendo a LSTM tem resultados melhores, contudo a GRU e mais r√°pida no treinamento mesmo que em determinados estudos o resultado da GRU tenha sido melhor.

State Space Models: Modelos recomendados para modelar s√©ries temporais que podem ser decompostas em estados latentes.

Tamb√©m como conclu√≠do por Aliene Nielsen (2021), modelos complicados nem sempre s√£o os melhores, pois o custo-benef√≠cio compensa o uso de recursos computacionais adicionais requeridos para sua opera√ß√£o.

Em uma an√°lise e defini√ß√£o de um modelo, e importante pensar se o tempo de treinamento adicional para operar com um modelo de aprendizagem de m√°quinas complexo valem a pena. 

Aliene Nielsen (2021) tamb√©m apresenta as diferen√ßas entre os modelos de series temporais univariadas e multivariadas, ou seja, series temporais univariadas possuem apenas uma vari√°vel medida ao longo do tempo, j√° as series temporais multivariadas s√£o series com m√∫ltiplas vari√°veis medidas a cada timestamp. Esta √∫ltima, s√£o muito uteis para an√°lise, pois muitas vezes as vari√°veis calculadas s√£o inter-relacionadas, e mostram depend√™ncias temporais entre si.

Neste estudo, a serie temporal base para o trabalho de Data Science, possui dados de temperatura e vibra√ß√£o de pequenos componentes da escavadeira Caterpillar 395, contudo, a an√°lise se concentrar√° em somente uma vari√°vel ao longo do tempo.

  - **3.5.	Trabalhos relacionados**

Inicialmente, e como comentado acima, este estudo foi aplicado sem quaisquer usos de tecnologia embarcada, e com a utiliza√ß√£o de um inspetor e uma c√¢mera tecnogr√°fica. 

  - **3.6.	Estudo de caso**

Este procedimento operacional requerido anteriormente, demandava uma s√©rie de atividades obrigat√≥rias para a compreens√£o de algum desvio nos par√¢metros, sendo seguidas todas as etapas de avalia√ß√£o de desempenho seguindo as diretrizes do fabricante tais como: 
‚Ä¢	Tempo de descida e subida do cilindro,
‚Ä¢	Press√£o hidr√°ulica durante os testes,
‚Ä¢	Taxa de fluxo das bombas hidr√°ulicas.
As Figuras 7a e b representam as press√µes hidr√°ulicas do equipamento, antes de realizar o teste de velocidade de descida e subida do implemento.

![Figura 7a. Temperatura do Fluido e Figura 7b. Press√£o Hidr√°ulica. Fonte: Pr√≥prio autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%207a.%20Temperatura%20do%20Fluido%20e%20Figura%207b.%20Press√£o%20Hidr√°ulica.png)

Somente ap√≥s estes pontos estarem dentro do par√¢metro especifica√ß√£o, o teste de temperatura por termografia foi conduzido, em paralelo aos testes de tempo de ciclo e press√£o.

Utilizando uma c√¢mera termogr√°fica para registrar o diferencial de temperatura dos cilindros eram feitas medi√ß√µes nas temperaturas, procurando identificar poss√≠veis diferencial t√©rmico foi entre os cilindros, neste caso, e conforme ilustrado na Figura 8, foi poss√≠vel identificar um diferencial de temperatura de 4,7¬∞C em rela√ß√£o ao lado esquerdo.

![Figura 8. Termografia nos Cilindros de Eleva√ß√£o da Escavadeira. Fonte: Pr√≥prio autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%207a.%20Temperatura%20do%20Fluido%20e%20Figura%207b.%20Press√£o%20Hidr√°ulica.png)

Os pontos mais quentes dos cilindros foram capturados pela c√¢mera, revelando uma diferen√ßa de temperatura de ~5¬∞C entre o cilindro de eleva√ß√£o do lado direito (l/d) e o cilindro de eleva√ß√£o do lado esquerdo (l/e) (Figura 9).

![Figura 9. Termogr√°fica com 5¬∞C entre os pontos dos cilindros de eleva√ß√£o da lan√ßa. Fonte: Pr√≥prio autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%209.%20Termogr√°fica%20com%205¬∞C%20entre%20os%20pontos%20dos%20cilindros%20de%20eleva√ß√£o%20da%20lan√ßa.png)

Ap√≥s remover e desmontar o cilindro na oficina de reparos, foi poss√≠vel confirmar que os sintomas observados no campo foram importantes para definir e concluir que o m√©todo termogr√°fico pode ser usado com mais seguran√ßa para determinar a necessidade de remo√ß√£o, conforme mostra a Figura 10 a seguir. Isso resultou em uma redu√ß√£o, embora n√£o significativa que iremos explicar mais a seguir, nos custos de reparo e no impacto na contamina√ß√£o do sistema hidr√°ulico.

![Figura 10. Cilindro na Centro de Reforma. Fonte: Pr√≥prio autor](G:\RNN_Sensor%20Dynamox\Git%20Reposit√≥rio\rnn-component-lIfe-cycle\rnn-component-lIfe-cycle-main\VsCode\Figura%2010.%20Cilindro%20na%20Centro%20de%20Reforma.png)

As Figuras 11a, 11b e 11c fornecem detalhes adicionais ap√≥s a desmontagem e an√°lise do cilindro, sendo que o modo de falha apresentado na Imagem 7 ilustra a causa do aumento de temperatura no processo termogr√°fico de campo.

![Figura 11¬™, b e c. Falha interna cilindro ap√≥s desmontagem e peritagem. Fonte: Pr√≥prio autor](G:\RNN_Sensor%20Dynamox\Git%20Reposit√≥rio\rnn-component-lIfe-cycle\rnn-component-lIfe-cycle-main\VsCode\Figura%2011a%20b%20e%20c.%20Falha%20interna%20Cilindro%20ap√≥s%20desmontagem.png)

Com isso, o que foi poss√≠vel entender √© que mesmo tendo sido avaliado antecipadamente, a frequ√™ncia em que foram realizadas as inspe√ß√µes e coletas em campo permitiram um avan√ßo da falha at√© um n√≠vel que o sistema j√° havia sido contaminado, apesar de ter sido removido antes de uma falha catastr√≥fica, tal abordagem permitiu avan√ßo nos significativos na parte interna do componente.

Ap√≥s os resultados utilizando fluxo anterior, e consequentemente com base na conclus√£o ap√≥s desmontagem e reforma, o principal questionamento a ser respondido foi, qual seria a forma de avan√ßar neste processo de coleta e an√°lise dos dados de temperatura a tempo de remover o componente, sem que ele possa estar em um estado de degrada√ß√£o avan√ßado? Como mitigar isso? Como antecipar a falha, a ponto de n√£o deixar esse Modo de Falha ocorrer?

  - **3.7.	M√©todos**
As etapas deste trabalho s√£o descritas a seguir no Figura 12, desde a an√°lise inicial at√© a conclus√£o.

![Figura 12. EAP projeto produto/processo. Fonte: Pr√≥prio autor](G:\RNN_Sensor%20Dynamox\Git%20Reposit√≥rio\rnn-component-lIfe-cycle\rnn-component-lIfe-cycle-main\VsCode\Figura%2012%20_%20EAP%20projeto%20produto%20processo.png)

  - **3.7.1.	Defini√ß√£o dos requisitos do projeto Brainstorm**

O projeto anterior, apresentado como parte de uma estrat√©gia de evoluir no monitoramento de pequenos componentes em campo, alguns pontos de evolu√ß√£o identificados, e s√£o apresentados a seguir na Figura 13 como sendo as poss√≠veis causas do avan√ßo na falha potencial do cilindro anteriormente analisado, e sugerido a√ß√µes para mitigar tais anormalidades.

![Figura 13. Ishikawa: An√°lise poss√≠veis causas. Fonte: Pr√≥prio autor](G:\RNN_Sensor%20Dynamox\Git%20Reposit√≥rio\rnn-component-lIfe-cycle\rnn-component-lIfe-cycle-main\VsCode\Figura%2013.%20Ishikawa%20An√°lise%20poss√≠veis%20causas.png)

  - **3.7.2.	Defini√ß√£o da tecnologia IoT**

Consequentemente, uma proposta de solu√ß√£o foi requerida, e esquematizada na Figura 14, com sendo um aprimoramento no processo de monitoramento, a fim de estruturar uma an√°lise robusta, com uso de tecnologia de sensoriamento online e m√©todos estat√≠sticos e suporte decis√≥rio mais s√≥lido. 

![Figura 14. New Online Data Collect. Fonte: Pr√≥prio autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%2014.%20New%20Online%20Data%20Collect.png)

  - **3.7.3.	Defini√ß√£o do equipamento/componentes para teste/valida√ß√£o em campo**

O equipamento/modelo definido para o piloto deste estudo em campo, foi a Escavadeira Hidr√°ulica Caterpillar 395 primeiramente, por ter sido o modelo de ativo utilizado no primeiro trabalho, utilizando a c√¢mera termogr√°fica apesentado na introdu√ß√£o desse estudo, segundo pela quantidade de ativos deste modelo em campo e terceiro pela sua criticidade para a produ√ß√£o nos clientes.

J√° os componentes, foram todos os pequenos componentes que n√£o possuem monitoramento direto pelo sistema embarcado do ativo.

Na Figura 15 temos a escavadeira Caterpillar 395 e os componentes definidos para monitoramento online.

![Figura 15. Escavadeira 395 e componentes a serem monitorados. Fonte: Pr√≥prio autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%2015.%20Escavadeira%20395%20e%20componentes%20a%20serem%20monitorados.png)

J√° para gerenciamento dos par√¢metros, foi definido uma estrutura de Sistema/Componentes conforme apresentado na Figura 16.

![Figura 16. Estrutura de sistemas/Componentes Modelo 395. Fonte: Pr√≥prio autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%2016.%20Estrutura%20de%20sistemas_Componentes%20Modelo%20395.png)
** Em verde, o componente definido para an√°lise neste estudo

  - **3.7.4.	Pontos de Instala√ß√£o e Coleta**

Para a an√°lise e apresenta√ß√£o dos resultados, foi utilizando alguns modelos de an√°lise estat√≠stica de series temporais, com foco nos dados coletados para os componentes Bomba Principal P1 e P2, como apresenta a Figura 17 a seguir, tanto por ser o componente mais cr√≠tico para o funcionamento do ativo pelo custo, impacto na disponibilidade f√≠sica e por causar um dado consequentes alto quando em uma parada n√£o programada.

Os dados de temperatura e vibra√ß√£o da bomba principal foram separados e tratados conforme apresentado a seguir, para posteriormente, ser elaborada a abordagem de Machine Learning mais apropriada.

![Figura 17. Componentes monitorados. Fonte: Pr√≥prio autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%2017.%20Componentes%20monitorados.png)

%pip install markdown
%pip install statsmodels
%pip install scikit-learn
%pip install PyGithub
%pip install gitpython
%pip install statsmodels
%pip install dash
%pip install xlwt
%pip install openpyxl
%pip install tensorflow
%pip install scipy


# Atualizar pacotes
import numpy as np
import os
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from IPython.display import Image
from sklearn.svm import SVR

from zipfile import ZipFile
from io import BytesIO
import requests

# URL do reposit√≥rio no GitHub
repo_url = 'https://github.com/CidClayQuirino/rnn-component-lIfe-cycle/archive/main.zip'
dataframes = []

# Baixe e extraia o arquivo zip do reposit√≥rio
response = requests.get(repo_url)
with ZipFile(BytesIO(response.content)) as zip_file:
    zip_file.extractall()

# Diret√≥rio onde os arquivos .xlsx foram extra√≠dos
extracted_dir = 'rnn-component-lIfe-cycle-main'

# Loop pelos arquivos no diret√≥rio extra√≠do
for arquivo in os.listdir(extracted_dir):
    if arquivo.endswith('.xlsx'):
        # Construa o caminho completo para o arquivo
        caminho_completo = os.path.join(extracted_dir, arquivo)

        # Leia o arquivo Excel e adicione-o √† lista de DataFrames
        df = pd.read_excel(caminho_completo)

        # Adicione uma coluna 'TagComp' contendo o nome do arquivo sem a extens√£o
        df['nome_arquivo'] = os.path.splitext(arquivo)[0]

        # Adicione o DataFrame √† lista
        dataframes.append(df)
# Concatene todos os DataFrames em um √∫nico DataFrame
BDadosTemp = pd.concat(dataframes, ignore_index=True)
BDadosTemp = BDadosTemp[(BDadosTemp != 0).all(axis=1)]
BDadosTemp['Value'] = BDadosTemp['Value'].round(1)
BDadosTemp = BDadosTemp.rename(columns={'Tag': 'Parametro'})
BDadosTemp = BDadosTemp.rename(columns={'nome_arquivo': 'NmeComp'})

# Filtrar as linhas onde a coluna 'NmeComp' √© igual a 'MainPumpP2' ou 'MainPumpP1'
df_MainPumps = BDadosTemp[BDadosTemp['NmeComp'].isin(['MainPumpP2', 'MainPumpP1'])]
#df_MainPumps = df_MainPumps.query("Parametro == 'Temperature'")

# Utilize o m√©todo groupby para agrupar os dados por 'NmeComp' e, em seguida, aplique describe() a cada grupo
summary = df_MainPumps.groupby('NmeComp').describe()

# Exiba a sumariza√ß√£o dos dados
print(df_MainPumps)

# Filtrar os dados para MainPumpP1 e MainPumpP2
df_MainPumpP1 = df_MainPumps[df_MainPumps['NmeComp'] == 'MainPumpP1']
df_MainPumpP2 = df_MainPumps[df_MainPumps['NmeComp'] == 'MainPumpP2']

# Filtrar as linhas onde a coluna 'NmeComp' √© igual a 'MainPumpP2' ou 'MainPumpP1'
df_MainPumpsTemp = df_MainPumps[df_MainPumps['Parametro'].isin(['Temperature'])]
#df_MainPumps = df_MainPumps.query("Parametro == 'Temperature'")

# Utilize o m√©todo groupby para agrupar os dados por 'NmeComp' e, em seguida, aplique describe() a cada grupo
summary = df_MainPumpsTemp.groupby('NmeComp').describe()

from scipy import stats
# Filtrar os valores correspondentes a 'MainPumpP1' e 'MainPumpP2'
df_MainPumpsTempP1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']['Value']
df_MainPumpsTempP2 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP2']['Value']
#calcular o Z-score para cada valor na Series de 'MainPumpP1'
z_scores_MainPumpsTempP1 = stats.zscore(df_MainPumpsTempP1)
# Definir um limite para o Z-score (por exemplo, 1 desvio padr√£o)
z_score_threshold = 0.2
# Encontrar os √≠ndices dos outliers para 'MainPumpP1'
outlier_indices_MainPumpsTempP1 = abs(z_scores_MainPumpsTempP1) > z_score_threshold
# Remover as linhas que cont√™m outliers para 'MainPumpP1'
dfZscore_MainPumpsTempP1 = df_MainPumpsTempP1[~outlier_indices_MainPumpsTempP1]
# Calcular o Z-score para cada valor na Series de 'MainPumpP2'
z_scores_MainPumpsTempP2 = stats.zscore(df_MainPumpsTempP2)
# Encontrar os √≠ndices dos outliers para 'MainPumpP2'
outlier_indices_MainPumpsTempP2 = abs(z_scores_MainPumpsTempP2) > z_score_threshold
# Remover as linhas que cont√™m outliers para 'MainPumpP2'
dfZscore_MainPumpsTempP2 = df_MainPumpsTempP2[~outlier_indices_MainPumpsTempP2]

import pandas as pd
# Aqui est√° um exemplo de como voc√™ poderia definir o outlier_threshold usando o intervalo interquartil (IQR):
Q1 = df_MainPumpsTemp['Value'].quantile(0.25)
Q3 = df_MainPumpsTemp['Value'].quantile(0.75)
IQR = Q3 - Q1
# Definir o limite para considerar algo como outlier
outlier_threshold = 0.2  # Pode ajustar conforme necess√°rio
# Calcular os limites inferior e superior para identificar outliers
lower_bound = Q1 - outlier_threshold * IQR
upper_bound = Q3 + outlier_threshold * IQR
# Filtrar os outliers sem remover os valores maximos superiores
df_filtered = df_MainPumpsTemp[(df_MainPumpsTemp['Value'] >= lower_bound)]
# Separar os resultados para os componentes 'MainPumpP1' e 'MainPumpP2'
df_MainPumpsTempP1IQR = df_filtered[df_filtered['NmeComp'] == 'MainPumpP1']
df_MainPumpsTempP2IQR = df_filtered[df_filtered['NmeComp'] == 'MainPumpP2']
# Coletar e registrar os valores m√≠nimos e m√°ximos para 'MainPumpP1'
min_MainPumpsTempP1 = df_MainPumpsTempP1IQR['Value'].min()
max_MainPumpsTempP1 = df_MainPumpsTempP1IQR['Value'].max()
# Coletar e registrar os valores m√≠nimos e m√°ximos para 'MainPumpP2'
min_MainPumpsTempP2 = df_MainPumpsTempP2IQR['Value'].min()
max_MainPumpsTempP2 = df_MainPumpsTempP2IQR['Value'].max()


  - **3.7.5.	ETL dados de temperatura Bombas Principais 1 e 2.**

A escavadeira de minera√ß√£o Caterpillar 395 foi selecionada por ser um ativo importante para a produ√ß√£o do cliente, oferecendo versatilidade e por ter sido o mesmo ativo utilizado no projeto anterior, onde a coleta foi feita manualmente. 

Assim, foram instalados os sensores nos componentes, conforme apresentado na Figura 18, e feita a integra√ß√£o com a base de dados da Dynamox, posteriormente foi feita a integra√ß√£o dos dados disponibilizadas na Cloud que iremos utilizar para a an√°lise dos dados de temperatura apresenta o comportamento apresentado no Figura 18 a seguir:

![Figura 18. Distribui√ß√£o das temperaturas das Bombas 1 e Bombas 2. Fonte: Pr√≥prio Autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%2018.%20Distribui√ß√£o%20das%20temperaturas%20das%20Bombas%201%20e%20Bombas%202.png)

A base de dados original fornecida pela plataforma da Dynamox possui a estrutura mostrada na Figura 19 a seguir, sendo necess√°rio um tratamento nos dados para seguirmos com a an√°lise e proje√ß√£o:

![Figura 19. Estrutura dos dados de temperatura e vibra√ß√£o. Fonte: Pr√≥prio Autor](G:/RNN_Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%2019.%20Estrutura%20dos%20dados%20de%20temperatura%20e%20vibra√ß√£o.png)

J√° na Figura 20 foram removidos os dados de Vibra√ß√£o para ambas as Bombas, para que este estudo de an√°lise de dados possamos focar somente na temperatura de ambas as bombas.

![Figura 20. Estrutura dos dados somente com a temperatura.Fonte: Pr√≥prio Autor](G:/RNN%20Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figura%2020.%20Estrutura%20dos%20dados%20somente%20com%20a%20temperatura.png)

Para estratifica√ß√£o e an√°lise dos dados foi utilizado o Software Python com interface do Google Colab. Iniciando pela avalia√ß√£o dos dados gerais, apresentado nas Figuras 21 e 22a seguir para a temperatura da Bomba Principal 1 e 2. 

Os dados analisados e apresentados no Figuras 21 a seguir, s√£o de um per√≠odo de 17 dias de coleta de temperaturas, iniciando em 11/03/2023 at√© 28/04/2023, compondo 8226 observa√ß√µes.

![Figuras 21. Resumo dados temperatura Bomba 1 e 2. Fonte: Pr√≥prio autor](G:/RNN%20Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figuras%2021.%20Resumo%20dados%20temperatura%20Bomba%201%20e%202.png)

J√° a dispers√£o dos dados √© apresentada no Figuras 22 e 23 a seguir, s√£o de um per√≠odo separadas pela bomba 1 e bomba 2,

![Figuras 22a e b. Perfil temperatura Bomba principal 1 e 2. Fonte: Pr√≥prio autor](G:/RNN%20Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figuras%2022a%20e%20b.%20Perfil%20temperatura%20Bomba%20principal%201%20e%202.png)

Na amostra coletada para este estudo, observou-se uma concentra√ß√£o de valores de temperatura formando uma ass√≠ntota a esquerda para os dados da Bomba 1, e uma ass√≠ntota a direita para os dados da Bomba 2.
Avan√ßando na an√°lise dos dados, utilizamos o pacote ‚Äúscikit-learn‚Äù que como apresentado no livro G√©ron, A. (2019) s√£o capazes de realizar tarefas de an√°lise de dados de regress√£o.

import pandas as pd
import matplotlib.pyplot as plt

# Filtrando os dados para MainPumpP1 e MainPumpP2
data_p1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']['Value']
data_p2 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP2']['Value']
# Configurando o layout dos subplots
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))
# Plotando o histograma para MainPumpP1
n1, bins1, patches1 = axes[0].hist(data_p1, bins=30, color='blue', alpha=0.5)
axes[0].set_title('Histograma MainPumpP1')
axes[0].set_xlabel('Frequ√™ncia Ocorr√™ncia MainPumpP1')
axes[0].set_ylabel('Valor de Temperatura')
# Adicionando os valores das barras para MainPumpP1
for rect1 in patches1:
    height1 = rect1.get_height()
    axes[0].text(rect1.get_x() + rect1.get_width()/2., height1, '%d' % int(height1),
            ha='center', va='bottom')
# Plotando o histograma para MainPumpP2
n2, bins2, patches2 = axes[1].hist(data_p2, bins=30, color='red', alpha=0.5)
axes[1].set_title('Histograma MainPumpP2')
axes[1].set_xlabel('Frequ√™ncia Ocorr√™ncia MainPumpP2')
axes[1].set_ylabel('Valor de Temperatura')
# Adicionando os valores das barras para MainPumpP2
for rect2 in patches2:
    height2 = rect2.get_height()
    axes[1].text(rect2.get_x() + rect2.get_width()/2., height2, '%d' % int(height2),
            ha='center', va='bottom')
# Ajustando o layout
plt.tight_layout()
# Exibindo os subplots
plt.show()


from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

df_MainPumpsTempP1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Selecionar o par√¢metro 'Value' como feature (X) e 'NmeComp' como o alvo (y)
X = df_MainPumpsTemp[['Value']].values
y = df_MainPumpsTemp['NmeComp']
# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Criar e treinar o modelo de √°rvore de decis√£o
tree_clf = DecisionTreeClassifier(max_depth=2)
tree_clf.fit(X_train, y_train)
# Fazer previs√µes no conjunto de teste
y_pred = tree_clf.predict(X_test)
# Calcular a precis√£o do modelo
accuracy = accuracy_score(y_test, y_pred)
print("Precis√£o do modelo:", accuracy)

df_MainPumps_Trans = df_MainPumpsTemp.pivot(index='Timestamp', columns='NmeComp', values='Value').reset_index()

import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Criar um novo dataframe com duas colunas do dataframe sem NA
BDadosTemp_MainPump = df_MainPumps_Trans[['MainPumpP1', 'MainPumpP2', 'Timestamp']].dropna()

# Adicionar uma coluna de dados sequenciais come√ßando em 1 at√© o n√∫mero de registros
BDadosTemp_MainPump['Sequence'] = range(1, len(BDadosTemp_MainPump) + 1)

# Criar subplots com plotly
fig_BDadosTemp_MainPump = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=['(C¬∞)MainPumpP1', '(C¬∞)MainPumpP2'])

# Adicionar traces para MainPumpP1
fig_BDadosTemp_MainPump.add_trace(go.Scatter(x=BDadosTemp_MainPump['Sequence'], y=BDadosTemp_MainPump['MainPumpP1'],
                                             mode='lines', fill='tozeroy', line=dict(color='blue'), name='(C¬∞)MainPumpP1'),
                                  row=1, col=1)

# Adicionar traces para MainPumpP2
fig_BDadosTemp_MainPump.add_trace(go.Scatter(x=BDadosTemp_MainPump['Sequence'], y=BDadosTemp_MainPump['MainPumpP2'],
                                             mode='lines', fill='tozeroy', line=dict(color='blue'), name='(C¬∞)MainPumpP2'),
                                  row=2, col=1)

# Definir limite m√°ximo para o eixo y como 125
fig_BDadosTemp_MainPump.update_yaxes(range=[0, 125], row=1, col=1)
fig_BDadosTemp_MainPump.update_yaxes(range=[0, 125], row=2, col=1)

# Atualizar layout com t√≠tulos personalizados e aumentar o tamanho das fontes
fig_BDadosTemp_MainPump.update_layout(
    title_text='Temperatura MainPumpP1 e MainPumpP2 ao longo do tempo',
    title_font_size=24,  # Tamanho da fonte do t√≠tulo
    showlegend=False,  # Desativar a legenda global
    height=800,  # Aumentar a altura do gr√°fico
    xaxis=dict(
        title='',
        titlefont=dict(size=24),  # Tamanho da fonte do t√≠tulo do eixo x
        tickfont=dict(size=22),  # Tamanho da fonte dos r√≥tulos do eixo x
    ),
    yaxis=dict(
        title='Temperatura (C¬∞)',
        titlefont=dict(size=24),  # Tamanho da fonte do t√≠tulo do eixo y
        tickfont=dict(size=22)  # Tamanho da fonte dos r√≥tulos do eixo y
    ),
    font=dict(size=20)  # Tamanho da fonte para o gr√°fico inteiro
)

# Ajustar o layout dos subplots
fig_BDadosTemp_MainPump.update_annotations(font_size=20)  # Tamanho da fonte dos t√≠tulos dos subplots

# Exibir o gr√°fico interativo
fig_BDadosTemp_MainPump.show()

  - **3.7.6.	Modelagem matem√°tica**

A seguir as Figuras 23a e b, mostra o teste de Dickey-Fuller, utilizando a biblioteca do python ‚Äúimport adfuller‚Äù para identificar o padr√£o estacion√°rio ou n√£o dos dados. Os resultados dessa an√°lise para a amostra de dados do estudo, apresentaram um Valor-p = 0.000003 para a Bomba P1 e de Valor-p = 0.000009 para a Bomba P2, est√£o muito pr√≥ximo de zero, ou seja, indicando que h√° forte evid√™ncia estat√≠stica para rejeitar a hip√≥tese nula de que a s√©rie √© n√£o estacion√°ria, ou seja, este resultado tanto para a Base de dados da Bomba 1 quanto para a Bomba 2, sugere-se que a s√©rie temporal seja estacion√°ria.

![Figuras 23a e b. Valor-p para dados Bomba 1 e 2.Fonte: Pr√≥prio Autor](G:/RNN%20Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figuras%2023a%20e%20b.%20Valor-p%20para%20dados%20Bomba%201%20e%202.png)


import pandas as pd
from statsmodels.tsa.stattools import adfuller

# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Primeiro, vamos filtrar a s√©rie temporal desejada (por exemplo, usando a coluna 'Parametro' para selecionar)
serie_temporalP1 = Df_Pump1['Value']
# Fun√ß√£o para testar estacionariedade da s√©rie temporal
def test_stationarity(timeseries):
    # Verificar se a s√©rie temporal n√£o est√° vazia
    if timeseries.empty:
        print("S√©rie temporal est√° vazia.")
        return
    # Estat√≠sticas de rolamento
    rolmean = timeseries.rolling(window=12).mean()
    rolstd = timeseries.rolling(window=12).std()
    # Plotar estat√≠sticas de rolamento
    import matplotlib.pyplot as plt
    plt.plot(timeseries, color='blue',label='Original')
    plt.plot(rolmean, color='red', label='M√©dia M√≥vel')
    plt.plot(rolstd, color='black', label = 'Desvio Padr√£o M√≥vel')
    plt.legend(loc='best')
    plt.title('Estat√≠sticas de Rolamento')
    plt.show()
    # Teste de Dickey-Fuller:
    print('Resultados do Teste Dickey-Fuller:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Estat√≠stica do Teste','Valor-p','#Lags Usados','N√∫mero de Observa√ß√µes Usadas'])
    for key,value in dftest[4].items():
        dfoutput['Valor Cr√≠tico (%s)'%key] = value
    print(dfoutput)
# Aplicar teste de estacionariedade √† s√©rie temporal selecionada
test_stationarity(serie_temporalP1)

import pandas as pd
from statsmodels.tsa.stattools import adfuller

# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump2 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP2']
# Primeiro, vamos filtrar a s√©rie temporal desejada (por exemplo, usando a coluna 'Parametro' para selecionar)
serie_temporalP2 = Df_Pump2['Value']
# Fun√ß√£o para testar estacionariedade da s√©rie temporal
def test_stationarity(timeseries):
    # Verificar se a s√©rie temporal n√£o est√° vazia
    if timeseries.empty:
        print("S√©rie temporal est√° vazia.")
        return
    # Estat√≠sticas de rolamento
    rolmean = timeseries.rolling(window=12).mean()
    rolstd = timeseries.rolling(window=12).std()
    # Plotar estat√≠sticas de rolamento
    import matplotlib.pyplot as plt
    plt.plot(timeseries, color='blue',label='Original')
    plt.plot(rolmean, color='red', label='M√©dia M√≥vel')
    plt.plot(rolstd, color='black', label = 'Desvio Padr√£o M√≥vel')
    plt.legend(loc='best')
    plt.title('Estat√≠sticas de Rolamento')
    plt.show()
    # Teste de Dickey-Fuller:
    print('Resultados do Teste Dickey-Fuller:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Estat√≠stica do Teste','Valor-p','#Lags Usados','N√∫mero de Observa√ß√µes Usadas'])
    for key,value in dftest[4].items():
        dfoutput['Valor Cr√≠tico (%s)'%key] = value
    print(dfoutput)
# Aplicar teste de estacionariedade √† s√©rie temporal selecionada
test_stationarity(serie_temporalP2)

import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Criar o DataFrame para armazenar os resultados
df_results_corelacao = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Calcular a correla√ß√£o entre as s√©ries temporais
correlation = Df_Pump1['Value'].corr(Df_Pump1['Value'].shift(1))
# Calcular as m√©tricas de erro (MAE, MSE, R^2)
y_true = Df_Pump1['Value'].iloc[1:]  # Remover o primeiro valor, pois n√£o h√° valor anterior para comparar
y_pred = Df_Pump1['Value'].shift(1).iloc[1:]  # Remover o primeiro valor, pois n√£o h√° valor anterior para comparar
mae = mean_absolute_error(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_corelacao.loc[len(df_results_corelacao)] = {'Modelo': 'Correla√ß√£o', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_corelacao)

import pandas as pd
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
#Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
#Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
df_results_SVR = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
#Definir as features (X) e o target (y)
X = Df_Pump1['Timestamp'].values.reshape(-1, 1) # Feature √© o timestamp
y = Df_Pump1['Value']
#Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#Treinar o modelo SVR
svr_model = SVR(kernel='rbf') # Use o kernel 'rbf' para SVR
svr_model.fit(X_train, y_train)
#Fazer previs√µes com o modelo SVR
y_pred_svr = svr_model.predict(X_test)
#Avaliar o desempenho do modelo SVR
mae = mean_absolute_error(y_test, y_pred_svr)
mse = mean_squared_error(y_test, y_pred_svr)
r2 = r2_score(y_test, y_pred_svr)
#Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_SVR.loc[len(df_results_SVR)] = {'Modelo': 'SVR', 'MAE': mae, 'MSE': mse, 'R2': r2}
#Exibir o DataFrame df_results
print(df_results_SVR)

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)

# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
df_results_ARIMA = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Definir os dados de treinamento e teste
train_size = int(len(Df_Pump1) * 0.8)  # 80% dos dados para treinamento
train_data = Df_Pump1['Value'].iloc[:train_size]
test_data = Df_Pump1['Value'].iloc[train_size:]
# Ajustar o modelo ARIMA aos dados de treinamento
order = (5, 1, 0)  # Par√¢metros p, d e q do ARIMA (ajuste conforme necess√°rio)
model = ARIMA(train_data, order=order)
arima_model = model.fit()
# Fazer previs√µes com o modelo ajustado
start_index = len(train_data)
end_index = start_index + len(test_data) - 1
predictions = arima_model.predict(start=start_index, end=end_index, typ='levels')
# Calcular as m√©tricas de erro (MAE, MSE, R^2)
mae = mean_absolute_error(test_data, predictions)
mse = mean_squared_error(test_data, predictions)
r2 = r2_score(test_data, predictions)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_ARIMA.loc[len(df_results_ARIMA)] = {'Modelo': 'ARIMA', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_ARIMA)

import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)

# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Inicializar o DataFrame para armazenar os resultados
df_results_ModelAR = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Ajustar o modelo AR aos dados de temperatura
lags = 1  # Especificando o n√∫mero de lags
X = Df_Pump1['Value'].shift(lags).dropna()  # Vari√°vel de entrada (com lag)
y = Df_Pump1['Value'][lags:]  # Vari√°vel de sa√≠da (sem lag)
# Dividir os dados em conjuntos de treinamento e teste
split_index = int(len(X) * 0.8)  # 80% dos dados para treinamento
X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]
# Ajustar o modelo AR aos dados de treinamento
model = sm.OLS(y_train, sm.add_constant(X_train))
ar_model = model.fit()
# Fazer previs√µes com o modelo ajustado
predictions = ar_model.predict(sm.add_constant(X_test))
# Calcular as m√©tricas de erro (MAE, MSE, R^2)
mae = mean_absolute_error(y_test, predictions)
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_ModelAR.loc[len(df_results_ModelAR)] = {'Modelo': 'Model AR', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_ModelAR)


import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Definir o tamanho da janela da M√©dia M√≥vel
window_size = 7  # Por exemplo, usar uma janela de 7 dias
# Calcular a M√©dia M√≥vel
Df_Pump1['Moving_Average'] = Df_Pump1['Value'].rolling(window=window_size).mean()
# Inicializar o DataFrame para armazenar os resultados
df_results_MediaMovel = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Remover os valores nulos resultantes da M√©dia M√≥vel
Df_Pump1.dropna(inplace=True)
# Calcular as m√©tricas de erro (MAE, MSE, R¬≤)
mae = mean_absolute_error(Df_Pump1['Value'], Df_Pump1['Moving_Average'])
mse = mean_squared_error(Df_Pump1['Value'], Df_Pump1['Moving_Average'])
r2 = r2_score(Df_Pump1['Value'], Df_Pump1['Moving_Average'])
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_MediaMovel.loc[len(df_results_MediaMovel)] = {'Modelo': 'Media Movel', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_MediaMovel)


import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import logging
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Configurar TensorFlow para ignorar avisos
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)

# Configurar logging para absl
logging.getLogger('tensorflow').setLevel(logging.ERROR)

# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Inicializar o DataFrame para armazenar os resultados
df_results_RNNLSTM = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Normalizar os dados
scaler = MinMaxScaler()
Df_Pump1['Value'] = scaler.fit_transform(Df_Pump1[['Value']])
# Fun√ß√£o para preparar os dados em sequ√™ncias para RNN
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)
# Definir o comprimento da sequ√™ncia (n√∫mero de passos de tempo)
seq_length = 10
# Criar sequ√™ncias de dados
X, y = create_sequences(Df_Pump1['Value'].values, seq_length)
# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Construir o modelo RNN
model = Sequential([
    LSTM(units=15, input_shape=(X_train.shape[1], 1)),
    Dense(1)
])
# Compilar o modelo
model.compile(optimizer='adam', loss='mean_squared_error')
# Treinar o modelo
model.fit(X_train, y_train, epochs=25, batch_size=32, verbose=1)
# Fazer previs√µes
predictions = model.predict(X_test)
# Calcular as m√©tricas de erro
mae = mean_absolute_error(y_test, predictions)
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_RNNLSTM.loc[len(df_results_RNNLSTM)] = {'Modelo': 'RNN-LSTM', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_RNNLSTM)


import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import logging
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Configurar TensorFlow para ignorar avisos
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)

# Configurar logging para absl
logging.getLogger('tensorflow').setLevel(logging.ERROR)
# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Inicializar o DataFrame para armazenar os resultados
df_results_RNNGRU = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Normalizar os dados
scaler = MinMaxScaler()
Df_Pump1['Value'] = scaler.fit_transform(Df_Pump1[['Value']])
# Fun√ß√£o para preparar os dados em sequ√™ncias para GRU
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)
# Definir o comprimento da sequ√™ncia (n√∫mero de passos de tempo)
seq_length = 10
# Criar sequ√™ncias de dados
X, y = create_sequences(Df_Pump1['Value'].values, seq_length)
# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Construir o modelo GRU
model = Sequential([
    GRU(units=15, input_shape=(X_train.shape[1], 1)),
    Dense(1)
])

# Compilar o modelo
model.compile(optimizer='adam', loss='mean_squared_error')
# Treinar o modelo
model.fit(X_train, y_train, epochs=25, batch_size=32, verbose=1)
# Fazer previs√µes
predictions = model.predict(X_test)
# Calcular as m√©tricas de erro
mae = mean_absolute_error(y_test, predictions)
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_RNNGRU.loc[len(df_results_RNNGRU)] = {'Modelo': 'RNN-GRU', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_RNNGRU)



import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import logging
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Configurar TensorFlow para ignorar avisos
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)

# Configurar logging para absl
logging.getLogger('tensorflow').setLevel(logging.ERROR)
# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Inicializar o DataFrame para armazenar os resultados
df_results_ExponentialSmoothing = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Ajustar o modelo de suaviza√ß√£o exponencial aos dados de temperatura
model = ExponentialSmoothing(Df_Pump1['Value'])
exp_smoothing_model = model.fit()
# Fazer previs√µes com o modelo ajustado
predictions = exp_smoothing_model.predict(start=len(Df_Pump1), end=len(Df_Pump1) + len(X_test) - 1)
# Calcular as m√©tricas de erro (MAE, MSE, R^2)
mae = mean_absolute_error(y_test, predictions)
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_ExponentialSmoothing.loc[len(df_results_ExponentialSmoothing)] = {'Modelo': 'Exponential Smoothing', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_ExponentialSmoothing)



import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import logging
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Configurar TensorFlow para ignorar avisos
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)

# Configurar logging para absl
logging.getLogger('tensorflow').setLevel(logging.ERROR)
# Separa√ß√£o dos dados de temperatura das Bombas P1 e P2
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Inicializar o DataFrame para armazenar os resultados
df_results_SARIMAX = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Ajustar o modelo SARIMAX aos dados de temperatura
order = (1, 0, 1)  # Ordem do modelo SARIMA (p, d, q)
seasonal_order = (1, 1, 1, 12)  # Ordem sazonal do modelo SARIMA (P, D, Q, S)
model = SARIMAX(Df_Pump1['Value'], order=order, seasonal_order=seasonal_order)
sarimax_model = model.fit()
# Fazer previs√µes com o modelo ajustado
predictions = sarimax_model.predict(start=len(Df_Pump1), end=len(Df_Pump1) + len(X_test) - 1)
# Calcular as m√©tricas de erro (MAE, MSE, R^2)
mae = mean_absolute_error(y_test, predictions)
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_SARIMAX.loc[len(df_results_SARIMAX)] = {'Modelo': 'SARIMAX', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_SARIMAX)


import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import logging
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Configurar TensorFlow para ignorar avisos
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)

# Configurar logging para absl
logging.getLogger('tensorflow').setLevel(logging.ERROR)
# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Converter a coluna 'Timestamp' para um formato num√©rico (por exemplo, n√∫mero de dias desde o in√≠cio da √©poca)
Df_Pump1['NumericTimestamp'] = Df_Pump1['Timestamp'].astype('int64') / 10**9 / 86400  # Converter nanossegundos para dias
# Definir as features (X) e o target (y)
X = Df_Pump1[['NumericTimestamp']]  # Feature √© o timestamp num√©rico
y = Df_Pump1['Value']
# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Ajustar o modelo de regress√£o linear aos dados de treinamento
model = LinearRegression()
model.fit(X_train, y_train)
# Fazer previs√µes com o modelo ajustado
y_pred = model.predict(X_test)
# Calcular as m√©tricas de erro (MAE, MSE, R^2)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
# Criar o DataFrame para armazenar os resultados
df_results_RLM = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_RLM.loc[len(df_results_RLM)] = {'Modelo': 'Regress√£o Linear M√∫ltipla', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_RLM)



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy.stats import uniform
import logging
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Configurar TensorFlow para ignorar avisos
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)

# Configurar logging para absl
logging.getLogger('tensorflow').setLevel(logging.ERROR)
# Criar o DataFrame para armazenar os resultados
df_results_SVR_Ajus = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Definir o n√∫mero de valores anteriores como 10% do volume de dados originais para proje√ß√£o
n_prev_values = int(0.10 * len(Df_Pump1))
# Criar features e target usando os √∫ltimos 10% dos dados
X = []
y = []
for i in range(n_prev_values, len(Df_Pump1)):
    X.append(Df_Pump1['Value'].values[i - n_prev_values:i])
    y.append(Df_Pump1['Value'].values[i])
X = np.array(X)
y = np.array(y)
# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Normalizar os dados
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
# Definir o modelo SVR
svr = SVR()
# Definir a grade de par√¢metros para RandomizedSearchCV
param_dist = {
    'C': uniform(0.1, 10),  # Ajuste a distribui√ß√£o de C
    'epsilon': uniform(0.01, 1),  # Ajuste a distribui√ß√£o de epsilon
    'kernel': ['linear', 'poly', 'rbf']
}
# Utilizar RandomizedSearchCV para encontrar os melhores par√¢metros
random_search = RandomizedSearchCV(svr, param_distributions=param_dist, n_iter=50, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, random_state=42)
random_search.fit(X_train, y_train)
# Melhor modelo
best_svr = random_search.best_estimator_
# Fazer previs√µes com o melhor modelo
y_pred = best_svr.predict(X_test)
# Calcular as m√©tricas de erro
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_SVR_Ajus.loc[len(df_results_SVR_Ajus)] = {'Modelo': 'SVR_1', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_SVR_Ajus)
print(f"Melhores Par√¢metros: {random_search.best_params_}")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print(f"R2: {r2}")



import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import logging
import warnings

# Suprimir avisos espec√≠ficos
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
# Configurar TensorFlow para ignorar avisos
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)

# Configurar logging para absl
logging.getLogger('tensorflow').setLevel(logging.ERROR)

# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Inicializar o DataFrame para armazenar os resultados
df_results_StateSpaceModel = pd.DataFrame(columns=['Modelo', 'MAE', 'MSE', 'R2'])
# Dividindo os dados em treinamento e teste
train_data, test_data = train_test_split(Df_Pump1, test_size=0.2, shuffle=False)
# Ajustando o modelo State Space Model (SSM)
model = sm.tsa.UnobservedComponents(train_data['Value'], 'local linear trend')
results = model.fit()
# Fazendo previs√µes
predictions = results.forecast(steps=len(test_data))
# Calculando as m√©tricas de erro
mae = mean_absolute_error(test_data['Value'], predictions)
mse = mean_squared_error(test_data['Value'], predictions)
r2 = r2_score(test_data['Value'], predictions)
# Adicionar as m√©tricas de erro ao DataFrame df_results_corelacao
df_results_StateSpaceModel.loc[len(df_results_StateSpaceModel)] = {'Modelo': 'State Space Model', 'MAE': mae, 'MSE': mse, 'R2': r2}
# Exibir o DataFrame df_results
print(df_results_StateSpaceModel)


A defini√ß√£o pela t√©cnica de AST&P (Advanced Statistical Techniques & Procedures) para an√°lise de dados e tomada de decis√£o foram feitos utilizando t√©cnicas estat√≠sticas cl√°ssicas e avan√ßadas. Dentre estes, o modelo mais aderente para trabalhar com s√©ries temporais lineares, depende de v√°rios fatores, incluindo a estrutura dos dados, a quantidade de dados dispon√≠veis, a presen√ßa de tend√™ncias ou sazonalidades, entre outros, contudo os modelos que foram testados para avaliar os resultados nessa s√©rie temporal de temperatura foram:

‚Ä¢	Regress√£o Linear Simples ou M√∫ltipla: A regress√£o linear √© um modelo simples que pode ser eficaz se houver uma rela√ß√£o linear direta entre as vari√°veis de entrada e sa√≠da.

‚Ä¢	Modelos Autoregressivos (AR): Modelos autorregressivos consideram a rela√ß√£o entre uma observa√ß√£o atual e observa√ß√µes passadas. Eles s√£o √∫teis quando h√° depend√™ncia temporal nas s√©ries temporais.

‚Ä¢	M√©dias M√≥veis (MA): Modelos de m√©dias m√≥veis consideram a rela√ß√£o entre uma observa√ß√£o e um erro residual das observa√ß√µes passadas. Eles podem ser combinados com modelos AR para formar modelos ARMA.

‚Ä¢	Modelos ARIMA (Autoregressive Integrated Moving Average): Modelos ARIMA combinam componentes de regress√£o autorregressiva, m√©dias m√≥veis e diferencia√ß√£o para modelar s√©ries temporais estacion√°rias ou com tend√™ncias conhecidas.

‚Ä¢	Suaviza√ß√£o Exponencial (Exponential Smoothing): Modelos recomendados para suavizar s√©ries temporais e capturar padr√µes sazonais.

‚Ä¢	Redes Neurais Recorrentes (RNNs): Modelos de redes neurais recorrentes, como LSTM e GRU, s√£o eficazes para capturar depend√™ncias de longo prazo em s√©ries temporais.

‚Ä¢	State Space Models: Modelos recomendados para modelar s√©ries temporais que podem ser decompostas em estados latentes.

Com base nos resultados obtidos tanto no teste de Dickey-Fuller quanto nos resultados de MAE, MSE e R2, como apresentado na Figuras 24, com os resultados consolidados dos modelos, e poss√≠vel identificar quais os modelos apresentam maior ader√™ncia aos dados coletados.

![Figuras 24. Resumo dados temperatura Bomba 1. Fonte: Pr√≥prio Autor](G:/RNN%20Sensor%20Dynamox/Git%20Reposit√≥rio/rnn-component-lIfe-cycle/rnn-component-lIfe-cycle-main/VsCode/Figuras%2024.%20Resumo%20dados%20temperatura%20Bomba%201.png)

As m√©tricas de desempenho para os diferentes modelos de previs√£o de s√©ries temporais aplicados aos dados de temperatura das bombas P1, foram avaliados em termos de tr√™s m√©tricas:
- MAE (Mean Absolute Error): Erro absoluto m√©dio, que mede a m√©dia dos erros absolutos entre os valores previstos e os valores reais. Valores menores indicam melhor desempenho.
- MSE (Mean Squared Error): Erro quadr√°tico m√©dio, que mede a m√©dia dos quadrados dos erros entre os valores previstos e os valores reais. Valores menores indicam melhor desempenho.
- R¬≤ (Coeficiente de Determina√ß√£o): Mede a propor√ß√£o da varia√ß√£o dos dados que √© explicada pelo modelo. Valores pr√≥ximos de 1 indicam um modelo que explica bem a varia√ß√£o dos dados, enquanto valores negativos indicam um modelo que est√° performando pior do que uma simples m√©dia.

State Space Model
- MAE: 1294.020169, MSE: 2.247582e+06, R¬≤: -4729.475731
*An√°lise:* Este modelo tem um desempenho extremamente ruim. O MAE √© muito alto, indicando previs√µes imprecisas. O MSE tamb√©m √© extremamente alto, e o R¬≤ negativo indica que o modelo est√° performando muito pior do que a m√©dia.

SARIMAX
- MAE: 13.243707, MSE: 2.736540e+02, R¬≤: -0.012671
*An√°lise:* O modelo SARIMAX tamb√©m n√£o performa bem, com um R¬≤ ligeiramente negativo e um MAE e MSE altos, indicando que n√£o √© um bom modelo para esses dados.

RNN-GRU
- MAE: 0.028991, MSE: 2.431490e-03, R¬≤: 0.948623
*An√°lise:* O modelo RNN-GRU apresenta um excelente desempenho, com um MAE muito baixo, um MSE extremamente baixos e um R¬≤ muito pr√≥ximo de 1, indicando que o modelo explica bem a varia√ß√£o dos dados.

RNN-LSTM
- MAE: 0.026283, MSE: 2.256681e-03, R¬≤: 0.952317
*An√°lise:* O modelo RNN-LSTM tamb√©m apresenta um desempenho excelente, similar ao GRU, com um MAE, MSE e R¬≤ muito bons.
Regress√£o Linear M√∫ltipla
- MAE: 12.297906, MSE: 2.145145e+02, R¬≤: 0.206178
*An√°lise:* Este modelo tem um desempenho mediano, com um MAE e MSE relativamente altos e um R¬≤ baixo, indicando que n√£o explica bem a varia√ß√£o dos dados.

M√©dia M√≥vel
- MAE: 2.440817, MSE: 1.502500e+01, R¬≤: 0.945099
*An√°lise:* A t√©cnica de m√©dia m√≥vel tem um bom desempenho, com um MAE razoavelmente baixo, um MSE baixo e um R¬≤ alto.

Modelo AR
- MAE: 5.576465, MSE: 8.251220e+01, R¬≤: 0.826393
*An√°lise:* O modelo AR (Autorregressivo) tem um desempenho decente, com um MAE e MSE moderados e um R¬≤ relativamente alto.

ARIMA
- MAE: 22.282574, MSE: 6.968059e+02, R¬≤: -0.466564
*An√°lise:* O modelo ARIMA n√£o performa bem, com um MAE e MSE altos e um R¬≤ negativo, indicando desempenho ruim.

SVR
- MAE: 9.104204, MSE: 1.485951e+02, R¬≤: 0.450116
*An√°lise:* O modelo SVR tem um desempenho razo√°vel, com um MAE e MSE moderados e um R¬≤ relativamente baixo.

SVR_Ajustado
- MAE: 1.866355, MSE: 1.356212e+01, R¬≤: 0.943082
*An√°lise:* O modelo SVR_Ajustado apresenta um desempenho muito bom, com um MAE baixo, um MSE baixo e um R¬≤ alto.

Exponential Smoothing
- MAE: 16.322945, MSE: 4.441108e+02, R¬≤: -0.643456
*An√°lise:* O modelo de suaviza√ß√£o exponencial n√£o performa bem, com um MAE e MSE altos e um R¬≤ negativo.

Correla√ß√£o
- MAE: 1.827380, MSE: 1.808035e+01, R¬≤: 0.933978
*An√°lise:* A t√©cnica de correla√ß√£o apresenta um bom desempenho, com um MAE baixo, um MSE relativamente baixo e um R¬≤ alto.

import pandas as pd

# Suponha que voc√™ tenha os DataFrames contendo os resultados de diferentes modelos
df_results = pd.concat([df_results_StateSpaceModel,
                        df_results_SARIMAX,
                        df_results_RNNGRU,
                        df_results_RNNLSTM,
                        df_results_RLM,
                        df_results_MediaMovel,
                        df_results_ModelAR,
                        df_results_ARIMA,
                        df_results_SVR,
                        df_results_SVR_Ajus,
                        df_results_ExponentialSmoothing,
                        df_results_corelacao], ignore_index=True)
# Exibir o DataFrame resultante
print(df_results)
df_results.head(10)

Neste caso, os modelos de RNN-GRU e RNN-LSTM obtiveram resultados bem mais aderentes ao modelo, com os menores MAE e MSE e os R¬≤ mais altos. Alinhado a isso, tamb√©m o modelo SVR_Ajustado com Randomized Search CV tamb√©m apresentou bom desempenho e foram definidos como sendo os m√©todos para proje√ß√£o dos dados.

Esta proje√ß√£o tem como objetivo fundamental, a identifica√ß√£o de quando os valores de temperatura podem atingir o limite de temperatura que indique uma falha potencial, conforme pode ser visto na Figuras 25 e Figuras 26.

import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Definir o n√∫mero de valores anteriores como 20% do volume de dados originais para c√°lculo da m√©dia hist√≥rica
n_prev_values_20 = int(0.10 * len(Df_Pump1))
# Calcular a m√©dia hist√≥rica dos √∫ltimos 20% dos dados
historical_mean = Df_Pump1['Value'].iloc[-n_prev_values_20:].mean()
upper_limit_value = historical_mean * 1.28
# Definir o n√∫mero de valores anteriores como 10% do volume de dados originais para proje√ß√£o
n_prev_values_10 = int(0.20 * len(Df_Pump1))
# Criar features e target usando os √∫ltimos 10% dos dados
X = []
y = []
for i in range(n_prev_values_10, len(Df_Pump1)):
    X.append(Df_Pump1['Value'].values[i - n_prev_values_10:i])
    y.append(Df_Pump1['Value'].values[i])

X = np.array(X)
y = np.array(y)
# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Treinar o modelo LinearRegression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
# Fazer previs√µes no conjunto de teste
y_pred_test = linear_model.predict(X_test)
# Calcular os res√≠duos
residuos = y_test - y_pred_test
# Criar um DataFrame para armazenar os res√≠duos
df_residuosSVM = pd.DataFrame({'y_true': y_test, 'y_pred': y_pred_test, 'residuos': residuos})
# Fazer previs√µes para o per√≠odo futuro
n_days_future = 100
# Criar um range cont√≠nuo de datas para previs√£o
future_dates = pd.date_range(start=Df_Pump1['Timestamp'].iloc[-1] + pd.Timedelta(seconds=1), periods=n_days_future, freq='D')
last_values = X[-1]  # √öltimos valores conhecidos
future_values = []
for _ in range(n_days_future):
    # Fazer previs√£o para o pr√≥ximo dia
    next_value = linear_model.predict([last_values])[0]
    future_values.append(next_value)

    # Atualizar os √∫ltimos valores conhecidos para incluir a nova previs√£o
    last_values = np.roll(last_values, -1)
    last_values[-1] = next_value
# Calcular os limites m√≠nimo e m√°ximo para o intervalo de confian√ßa
std_residuals = np.std(y_test - y_pred_test)  # Desvio padr√£o dos res√≠duos
z_critical = 1.96  # Para intervalo de confian√ßa de 95%
lower_bound = np.array(future_values) - z_critical * std_residuals
upper_bound = np.array(future_values) + z_critical * std_residuals
# Criar DataFrame com as previs√µes
df_future = pd.DataFrame({'Timestamp': future_dates, 'Value': future_values, 'Lower_Bound': lower_bound, 'Upper_Bound': upper_bound})
# Criar o gr√°fico interativo com Plotly
fig = go.Figure()
# Adicionar os dados originais
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=Df_Pump1['Value'], mode='lines', name='Dados Originais'))
# Adicionar a linha de limite superior (25% acima da m√©dia hist√≥rica dos √∫ltimos 20% dos dados)
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=[upper_limit_value]*len(Df_Pump1), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico'))
# Adicionar a proje√ß√£o e o intervalo de confian√ßa
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=df_future['Value'], mode='lines', name='Proje√ß√£o'))
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=df_future['Lower_Bound'], mode='lines', line=dict(width=0), marker=dict(color="#444"), name='Limite Inferior'))
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=df_future['Upper_Bound'], mode='lines', line=dict(width=0), marker=dict(color="#444"), fillcolor='rgba(68, 68, 68, 0.3)', fill='tonexty', name='Limite Superior'))
# Adicionar a linha de limite superior tamb√©m na proje√ß√£o
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=[upper_limit_value]*len(df_future), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico Proje√ß√£o'))
# Personalizar o layout, incluindo o tamanho da fonte
fig.update_layout(
    title={
        'text': 'Proje√ß√£o de Temperatura com Regress√£o Linear e Intervalo de Confian√ßa',
        'font': {'size': 24}
    },
    xaxis_title={
        'text': 'Timestamp',
        'font': {'size': 20}
    },
    yaxis_title={
        'text': 'Value',
        'font': {'size': 20}
    },
    hovermode='x',
    template='plotly_white',
    font=dict(size=16)  # Aumentar o tamanho da fonte para outros elementos
)
fig.show()
# Mostrar os res√≠duos
print(df_residuosSVM.head())


import warnings
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.regularizers import l1, l2
from sklearn.metrics import mean_squared_error
import logging
import os

# Suprimir avisos
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)

# Configurar TensorFlow para ignorar mensagens de log menos importantes
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)
logging.getLogger('tensorflow').setLevel(logging.ERROR)

# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']

# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])

# Definir o n√∫mero de valores anteriores como 20% do volume de dados originais para c√°lculo da m√©dia hist√≥rica
n_prev_values_20 = int(0.10 * len(Df_Pump1))

# Calcular a m√©dia hist√≥rica dos √∫ltimos 20% dos dados
historical_mean = Df_Pump1['Value'].iloc[-n_prev_values_20:].mean()
upper_limit_value = historical_mean * 1.28

# Definir o n√∫mero de valores anteriores como 10% do volume de dados originais para proje√ß√£o
n_prev_values_10 = int(0.75 * len(Df_Pump1))

# Criar features e target usando os √∫ltimos 10% dos dados
X = []
y = []
for i in range(n_prev_values_10, len(Df_Pump1)):
    X.append(Df_Pump1['Value'].values[i - n_prev_values_10:i])
    y.append(Df_Pump1['Value'].values[i])
X = np.array(X)
y = np.array(y)

# Expandir as dimens√µes de X para ser compat√≠vel com LSTM (n√∫mero de amostras, passos de tempo, n√∫mero de features)
X = np.expand_dims(X, axis=-1)

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Criar o modelo LSTM com L1, L2 e Dropout
model = Sequential()
model.add(LSTM(100, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]),
               kernel_regularizer=l1(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(1))

# Compilar o modelo
model.compile(optimizer='adam', loss='mse')

# Treinar o modelo
model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test))

# Fazer previs√µes no conjunto de teste
y_pred_test = model.predict(X_test)

# Calcular os res√≠duos
residuos = y_test - y_pred_test.flatten()

# Criar um DataFrame para armazenar os res√≠duos
df_residuosLSTM = pd.DataFrame({'y_true': y_test, 'y_pred': y_pred_test.flatten(), 'residuos': residuos})

# Fazer previs√µes para os pr√≥ximos 10 passos de tempo
n_days_future = 100
last_sequence = X[-1]  # √öltima sequ√™ncia conhecida nos √∫ltimos 10% dos dados
future_values = []
for _ in range(n_days_future):
    # Prever o pr√≥ximo valor
    next_value = model.predict(np.expand_dims(last_sequence, axis=0))[0, 0]
    future_values.append(next_value)

    # Atualizar a sequ√™ncia conhecida para incluir a nova previs√£o
    last_sequence = np.roll(last_sequence, -1)
    last_sequence[-1, 0] = next_value

# Criar datas futuras para plotagem
future_dates = pd.date_range(start=Df_Pump1['Timestamp'].iloc[-1] + pd.Timedelta(seconds=1), periods=n_days_future, freq='D')

# Criar DataFrame com as previs√µes
df_future = pd.DataFrame({'Timestamp': future_dates, 'Value': future_values})

# Criar o gr√°fico interativo com Plotly
fig = go.Figure()

# Adicionar os dados originais
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=Df_Pump1['Value'], mode='lines', name='Dados Originais'))

# Adicionar a linha de limite superior (25% acima da m√©dia hist√≥rica dos √∫ltimos 20% dos dados)
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=[upper_limit_value]*len(Df_Pump1), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico'))

# Adicionar a proje√ß√£o
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=df_future['Value'], mode='lines', name='Proje√ß√£o'))

# Adicionar a linha de limite superior tamb√©m na proje√ß√£o
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=[upper_limit_value]*len(df_future), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico Proje√ß√£o'))

# Personalizar o layout, incluindo o tamanho da fonte
fig.update_layout(
    title={
        'text': 'Proje√ß√£o de Temperatura com LSTM e Intervalo de Confian√ßa',
        'font': {'size': 24}
    },
    xaxis_title={
        'text': 'Timestamp',
        'font': {'size': 20}
    },
    yaxis_title={
        'text': 'Value',
        'font': {'size': 20}
    },
    hovermode='x',
    template='plotly_white',
    font=dict(size=16)  # Aumentar o tamanho da fonte para outros elementos
)

fig.show()

# Mostrar os res√≠duos
print(df_residuosLSTM.head())


import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout
from tensorflow.keras.regularizers import l1, l2
from sklearn.metrics import mean_squared_error

# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']
# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])
# Definir o n√∫mero de valores anteriores como 10% do volume de dados originais para c√°lculo da m√©dia hist√≥rica
n_prev_values_20 = int(0.10 * len(Df_Pump1))
# Calcular a m√©dia hist√≥rica dos √∫ltimos 20% dos dados
historical_mean = Df_Pump1['Value'].iloc[-n_prev_values_20:].mean()
upper_limit_value = historical_mean * 1.28
# Definir o n√∫mero de valores anteriores como 50% do volume de dados originais para proje√ß√£o
n_prev_values_10 = int(0.50 * len(Df_Pump1))
# Criar features e target usando os √∫ltimos 10% dos dados
X = []
y = []
for i in range(n_prev_values_10, len(Df_Pump1)):
    X.append(Df_Pump1['Value'].values[i - n_prev_values_10:i])
    y.append(Df_Pump1['Value'].values[i])
X = np.array(X)
y = np.array(y)
# Expandir as dimens√µes de X para ser compat√≠vel com GRU (n√∫mero de amostras, passos de tempo, n√∫mero de features)
X = np.expand_dims(X, axis=-1)
# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Criar o modelo GRU com L1, L2 e Dropout
model = Sequential()
model.add(GRU(100, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]),
              kernel_regularizer=l1(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(1))
# Compilar o modelo
model.compile(optimizer='adam', loss='mse')
# Treinar o modelo
model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test))
# Fazer previs√µes no conjunto de teste
y_pred_test = model.predict(X_test)
# Calcular os res√≠duos
residuos = y_test - y_pred_test.flatten()
# Criar um DataFrame para armazenar os res√≠duos
df_residuosGRU = pd.DataFrame({'y_true': y_test, 'y_pred': y_pred_test.flatten(), 'residuos': residuos})
# Fazer previs√µes para os pr√≥ximos 100 passos de tempo
n_days_future = 100
last_sequence = X[-1]  # √öltima sequ√™ncia conhecida nos √∫ltimos 10% dos dados
future_values = []
for _ in range(n_days_future):
    # Prever o pr√≥ximo valor
    next_value = model.predict(np.expand_dims(last_sequence, axis=0))[0, 0]
    future_values.append(next_value)

    # Atualizar a sequ√™ncia conhecida para incluir a nova previs√£o
    last_sequence = np.roll(last_sequence, -1)
    last_sequence[-1, 0] = next_value
# Criar datas futuras para plotagem
future_dates = pd.date_range(start=Df_Pump1['Timestamp'].iloc[-1] + pd.Timedelta(seconds=1), periods=n_days_future, freq='D')
# Criar DataFrame com as previs√µes
df_future = pd.DataFrame({'Timestamp': future_dates, 'Value': future_values})
# Criar o gr√°fico interativo com Plotly
fig = go.Figure()
# Adicionar os dados originais
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=Df_Pump1['Value'], mode='lines', name='Dados Originais'))
# Adicionar a linha de limite superior (25% acima da m√©dia hist√≥rica dos √∫ltimos 20% dos dados)
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=[upper_limit_value]*len(Df_Pump1), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico'))
# Adicionar a proje√ß√£o
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=df_future['Value'], mode='lines', name='Proje√ß√£o'))
# Adicionar a linha de limite superior tamb√©m na proje√ß√£o
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=[upper_limit_value]*len(df_future), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico Proje√ß√£o'))
# Personalizar o layout, incluindo o tamanho da fonte
fig.update_layout(
    title={
        'text': 'Proje√ß√£o de Temperatura com GRU e Intervalo de Confian√ßa',
        'font': {'size': 24}
    },
    xaxis_title={
        'text': 'Timestamp',
        'font': {'size': 20}
    },
    yaxis_title={
        'text': 'Value',
        'font': {'size': 20}
    },
    hovermode='x',
    template='plotly_white',
    font=dict(size=16)  # Aumentar o tamanho da fonte para outros elementos
)
fig.show()
# Mostrr os res√≠duos
print(df_residuosGRU.head())



import pandas as pd
from github import Github
from io import BytesIO

# Defina suas credenciais do GitHub
seu_token = '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'
seu_usuario = 'CidClayQuirino'
seu_repositorio = 'rnn-component-lIfe-cycle'
# Dicion√°rio de DataFrames com seus nomes originais
dataframes = {
    'df_MainPumpsTemp': df_MainPumpsTemp,
    'df_MainPumps': df_MainPumps,
    'df_results': df_results,
    'BDadosTemp':BDadosTemp,
    'df_residuosGRU':df_residuosGRU,
    'df_residuosSVM':df_residuosSVM,
    'df_residuosLSTM':df_residuosLSTM, 
    'df_residuosGRU': df_residuosGRU,
    'df_residuosLSTM':df_residuosLSTM,
    'df_residuosSVM': df_residuosSVM,
 }

# Fun√ß√£o para salvar e enviar para o GitHub
def salvar_e_enviar_para_github(dataframe, nome_arquivo, usuario, repositorio, token):
    # Salvar DataFrame como CSV em um BytesIO
    csv_bytes = BytesIO()
    dataframe.to_csv(csv_bytes, index=False)

    # Autenticar no GitHub
    g = Github(token)

    # Obter o reposit√≥rio
    repo = g.get_user(usuario).get_repo(repositorio)

    # Criar ou atualizar o arquivo no reposit√≥rio
    try:
        arquivo = repo.get_contents(nome_arquivo)
        repo.update_file(nome_arquivo, f'Atualizando {nome_arquivo}', csv_bytes.getvalue(), arquivo.sha)
        print(f'{nome_arquivo} atualizado com sucesso!')
    except Exception as e:
        repo.create_file(nome_arquivo, f'Adicionando {nome_arquivo}', csv_bytes.getvalue())
        print(f'{nome_arquivo} criado com sucesso!')

# Iterar sobre os DataFrames e salv√°-los no GitHub
for nome, df in dataframes.items():
    nome_arquivo = f'{nome}.csv'  # Nome do arquivo usando o nome original do DataFrame
    salvar_e_enviar_para_github(df, nome_arquivo, seu_usuario, seu_repositorio, seu_token)


An√°lise de Res√≠duos pelo teste de Shapiro-Wilk (shapiro()) a fim de verificar:
 - M√©dia dos Res√≠duos
 - Dispers√£o dos Res√≠duos
 - Res√≠duos Extremos
 - Quartis

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import shapiro

# Carregar os dados
#df_residuosGRU = pd.read_csv('df_residuosGRU.csv')
#df_residuosSVM = pd.read_csv('df_residuosSVM.csv')
#df_residuosLSTM = pd.read_csv('df_residuosLSTM.csv')

# Fun√ß√£o para realizar o teste de Shapiro-Wilk e exibir o resultado
def shapiro_test(residuos, model_name):
    stat, p_value = shapiro(residuos)
    print(f'Teste de Shapiro-Wilk para {model_name}:')
    print(f'Estat√≠stica={stat}, p-valor={p_value}\n')
    return stat, p_value

# Realizar o teste de Shapiro-Wilk nos res√≠duos
stat_gru, p_gru = shapiro_test(df_residuosGRU['residuos'], 'GRU')
stat_svm, p_svm = shapiro_test(df_residuosSVM['residuos'], 'SVM')
stat_lstm, p_lstm = shapiro_test(df_residuosLSTM['residuos'], 'LSTM')

# Plotar histogramas dos res√≠duos
plt.figure(figsize=(18, 6))

plt.subplot(1, 3, 1)
sns.histplot(df_residuosGRU['residuos'], kde=True, color='blue')
plt.title('Histograma dos Res√≠duos - GRU')
plt.xlabel('Res√≠duos')
plt.ylabel('Frequ√™ncia')

plt.subplot(1, 3, 2)
sns.histplot(df_residuosSVM['residuos'], kde=True, color='green')
plt.title('Histograma dos Res√≠duos - SVM')
plt.xlabel('Res√≠duos')
plt.ylabel('Frequ√™ncia')

plt.subplot(1, 3, 3)
sns.histplot(df_residuosLSTM['residuos'], kde=True, color='red')
plt.title('Histograma dos Res√≠duos - LSTM')
plt.xlabel('Res√≠duos')
plt.ylabel('Frequ√™ncia')

plt.tight_layout()
plt.show()

# Plotar gr√°ficos de dispers√£o dos res√≠duos
plt.figure(figsize=(18, 6))

plt.subplot(1, 3, 1)
plt.scatter(range(len(df_residuosGRU)), df_residuosGRU['residuos'], color='blue')
plt.axhline(0, color='red', linestyle='--')
plt.title('Gr√°fico de Dispers√£o dos Res√≠duos - GRU')
plt.xlabel('√çndice')
plt.ylabel('Res√≠duos')

plt.subplot(1, 3, 2)
plt.scatter(range(len(df_residuosSVM)), df_residuosSVM['residuos'], color='green')
plt.axhline(0, color='red', linestyle='--')
plt.title('Gr√°fico de Dispers√£o dos Res√≠duos - SVM')
plt.xlabel('√çndice')
plt.ylabel('Res√≠duos')

plt.subplot(1, 3, 3)
plt.scatter(range(len(df_residuosLSTM)), df_residuosLSTM['residuos'], color='red')
plt.axhline(0, color='red', linestyle='--')
plt.title('Gr√°fico de Dispers√£o dos Res√≠duos - LSTM')
plt.xlabel('√çndice')
plt.ylabel('Res√≠duos')

plt.tight_layout()
plt.show()

# Estat√≠sticas descritivas dos res√≠duos
print("Estat√≠sticas descritivas dos res√≠duos - GRU")
print(df_residuosGRU['residuos'].describe())
print("\nEstat√≠sticas descritivas dos res√≠duos - SVM")
print(df_residuosSVM['residuos'].describe())
print("\nEstat√≠sticas descritivas dos res√≠duos - LSTM")
print(df_residuosLSTM['residuos'].describe())

Os resultados apresentados no teste de Shapiro-Wilk para GRU, LSTM e SVM, 
 - M√©dia dos Res√≠duos: A m√©dia dos res√≠duos √© pr√≥xima de zero para SVM (-0.10) e LSTM (0.31), indicando que, em m√©dia, as previs√µes n√£o est√£o muito deslocadas dos valores reais. A m√©dia dos res√≠duos do GRU (1.08) √© ligeiramente maior, sugerindo um pequeno vi√©s nas previs√µes.
 - Dispers√£o dos Res√≠duos: O desvio padr√£o dos res√≠duos √© menor para o modelo LSTM (3.75), sugerindo que as previs√µes do LSTM s√£o mais consistentes e t√™m menor variabilidade. O desvio padr√£o √© maior para o modelo SVM (6.46), indicando maior variabilidade nas previs√µes.
 - Res√≠duos Extremos: Os res√≠duos m√≠nimos e m√°ximos s√£o maiores para o modelo SVM, sugerindo a presen√ßa de outliers ou erros de previs√£o mais extremos. O GRU e LSTM t√™m menores extremos em compara√ß√£o ao SVM, com LSTM apresentando os menores valores de res√≠duos extremos.
 - Quartis:Os quartis (25%, 50%, 75%) indicam a distribui√ß√£o dos res√≠duos. O SVM tem a maior dispers√£o interquartil (IQR), seguido pelo GRU e LSTM.

TESTE: Incluir Tend√™ncia na Previs√£o: Explicitamente adicionar uma componente de tend√™ncia aos valores previstos.

C√°lculo da Tend√™ncia:

Calcula a tend√™ncia usando uma regress√£o linear nos √∫ltimos 15% dos dados.
  -n_last_values define o n√∫mero de √∫ltimos valores a serem usados para calcular a tend√™ncia.
  - reg.coef_[0] fornece o coeficiente angular da regress√£o linear, que √© usado como a tend√™ncia.

Adi√ß√£o da Tend√™ncia:

No loop de previs√£o, next_value += trend adiciona a tend√™ncia calculada ao pr√≥ximo valor previsto.
Valida√ß√£o da Tend√™ncia:

Imprime o valor do coeficiente angular para valida√ß√£o.


import warnings
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.regularizers import l1, l2
from sklearn.metrics import mean_squared_error
import logging
import os

# Suprimir avisos
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)

# Configurar TensorFlow para ignorar mensagens de log menos importantes
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.get_logger().setLevel(logging.ERROR)
logging.getLogger('tensorflow').setLevel(logging.ERROR)

# Separa√ß√£o dos dados de temperatura das Bombas P1
Df_Pump1 = df_MainPumpsTemp[df_MainPumpsTemp['NmeComp'] == 'MainPumpP1']

# Converter a coluna 'Timestamp' para o tipo datetime, se necess√°rio
Df_Pump1['Timestamp'] = pd.to_datetime(Df_Pump1['Timestamp'])

# Definir o n√∫mero de valores anteriores como 20% do volume de dados originais para c√°lculo da m√©dia hist√≥rica
n_prev_values_20 = int(0.10 * len(Df_Pump1))

# Calcular a m√©dia hist√≥rica dos √∫ltimos 20% dos dados
historical_mean = Df_Pump1['Value'].iloc[-n_prev_values_20:].mean()
upper_limit_value = historical_mean * 1.28

# Definir o n√∫mero de valores anteriores como 10% do volume de dados originais para proje√ß√£o
n_prev_values_10 = int(0.25 * len(Df_Pump1))

# Criar features e target usando os √∫ltimos 10% dos dados
X = []
y = []
for i in range(n_prev_values_10, len(Df_Pump1)):
    X.append(Df_Pump1['Value'].values[i - n_prev_values_10:i])
    y.append(Df_Pump1['Value'].values[i])
X = np.array(X)
y = np.array(y)

# Expandir as dimens√µes de X para ser compat√≠vel com LSTM (n√∫mero de amostras, passos de tempo, n√∫mero de features)
X = np.expand_dims(X, axis=-1)

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Criar o modelo LSTM com L1, L2 e Dropout
model = Sequential()
model.add(LSTM(100, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]),
               kernel_regularizer=l1(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(1))

# Compilar o modelo
model.compile(optimizer='adam', loss='mse')

# Treinar o modelo
model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test))

# Fazer previs√µes no conjunto de teste
y_pred_test = model.predict(X_test)

# Fazer previs√µes para os pr√≥ximos 100 passos de tempo
n_days_future = 100
last_sequence = X[-1]  # √öltima sequ√™ncia conhecida nos √∫ltimos 10% dos dados
future_values = []
trend = 0.2  # Ajustar a tend√™ncia conforme necess√°rio

for _ in range(n_days_future):
    # Prever o pr√≥ximo valor
    next_value = model.predict(np.expand_dims(last_sequence, axis=0))[0, 0]
    next_value += trend  # Adicionar a tend√™ncia

    future_values.append(next_value)

    # Atualizar a sequ√™ncia conhecida para incluir a nova previs√£o
    last_sequence = np.roll(last_sequence, -1)
    last_sequence[-1, 0] = next_value

# Criar datas futuras para plotagem
future_dates = pd.date_range(start=Df_Pump1['Timestamp'].iloc[-1] + pd.Timedelta(seconds=1), periods=n_days_future, freq='D')

# Criar DataFrame com as previs√µes
df_future = pd.DataFrame({'Timestamp': future_dates, 'Value': future_values})

# Criar o gr√°fico interativo com Plotly
fig = go.Figure()

# Adicionar os dados originais
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=Df_Pump1['Value'], mode='lines', name='Dados Originais'))

# Adicionar a linha de limite superior (25% acima da m√©dia hist√≥rica dos √∫ltimos 20% dos dados)
fig.add_trace(go.Scatter(x=Df_Pump1['Timestamp'], y=[upper_limit_value]*len(Df_Pump1), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico'))

# Adicionar a proje√ß√£o
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=df_future['Value'], mode='lines', name='Proje√ß√£o'))

# Adicionar a linha de limite superior tamb√©m na proje√ß√£o
fig.add_trace(go.Scatter(x=df_future['Timestamp'], y=[upper_limit_value]*len(df_future), mode='lines', line=dict(color='red', dash='dash'), name='Limite Superior Hist√≥rico Proje√ß√£o'))

# Personalizar o layout, incluindo o tamanho da fonte
fig.update_layout(
    title={
        'text': 'Proje√ß√£o de Temperatura com LSTM e Intervalo de Confian√ßa',
        'font': {'size': 24}
    },
    xaxis_title={
        'text': 'Timestamp',
        'font': {'size': 20}
    },
    yaxis_title={
        'text': 'Value',
        'font': {'size': 20}
    },
    hovermode='x',
    template='plotly_white',
    font=dict(size=16)  # Aumentar o tamanho da fonte para outros elementos
)

fig.show()


**4.	Resultados e Discuss√µes**

Com base nos resultados apresentados para a amostra de dados coletados, os modelos estudados anteriormente apresentaram diferentes comportamentos, sendo que os modelos de aprendizado de m√°quina RNN-GRU e RNN-LSTM apresentaram o melhor desempenho em termos de m√©tricas de erro (MAE e MSE) e explica√ß√£o da vari√¢ncia (R2), ou seja, estes modelos foram capazes de capturar padr√µes complexos nos dados temporais.

Muito pr√≥ximo aos resultados dos modelos de aprendizado est√° o modelo de M√©dia M√≥vel, que tamb√©m obteve um bom desempenho, como esperado, com baixas m√©tricas de erro e um R2 alto, sugerindo como um modelo simples como a m√©dia m√≥vel pode ser eficaz na previs√£o de s√©ries temporais em certos casos.

Por outro lado, o modelo ARIMA apresentou um desempenho relativamente ruim em compara√ß√£o com demais, tendo resultado em altos valores de MAE e MSE e um R2 negativo, o que indica que o modelo ARIMA pode n√£o ter sido capaz de capturar adequadamente a estrutura dos dados de temperatura para a Bomba 1.

J√° o caso dos modelos de regress√£o linear m√∫ltipla e SVR, estes mostraram desempenho intermedi√°rio, com valores moderados de MAE, MSE e R2, podendo ser mais bem estudado para ajustar os dados aos requisites destes modelos.

Complementando a an√°lise, os modelos de State Space Model, SARIMAX e Exponential Smoothing apresentaram um desempenho inferior em compara√ß√£o com outros m√©todos, com valores relativamente altos de MAE e MSE e R2 negativos, indicando que estes modelos podem n√£o ser adequados para capturar a complexidade dos dados temporais de temperatura para a Bomba 1.

Portanto, para o conjunto de dados considerados neste estudo, os modelos RNN-GRU e RNN-LSTM e o Modelo SVR com Randomized Search CV foram os mais adequados considerando o ajuste dos MAE e MSE e R2 aos dados coletados, sendo os mais adequados para realizar previs√µes. 

Em contrapartida, os tempos de processamento para os modelos os modelos RNN-GRU e RNN-LSTM foram consideravelmente altos, indicando a necessidade de aprofundamento sobre o impacto deste tempo, quando na an√°lise dos dados cont√≠nuos.

Normalidade dos Res√≠duos: Nenhum dos modelos possui res√≠duos normalmente distribu√≠dos.

Desempenho Relativo: O modelo LSTM parece ter uma melhor performance em termos de menor variabilidade dos res√≠duos e menor presen√ßa de 
outliers.

Ajuste do Modelo: Pode ser necess√°rio ajustar ou refinar os modelos, ou considerar transforma√ß√µes nos dados para melhorar a normalidade e reduzir a variabilidade dos res√≠duos.

Os pequenos componentes dos ativos de minera√ß√£o considerados neste estudo, n√£o possuem monitoramento que possibilite antecipar anormalidades, e consequentemente auxiliar na identifica√ß√£o de falhas prematuras. 

As poss√≠veis an√°lises s√£o feitas por inspe√ß√£o sensitiva e ou avalia√ß√µes indiretas de par√¢metros relacionados aos sistemas, que s√£o registrados em relat√≥rios mensais e nos backlogs di√°rios. Os resultados obtidos nas coletas de dados apresentam resultados potenciais e que podem ser utilizadas para identificar com maior assertividade, o momento √≥timo de manuten√ß√£o ou realizar uma melhoria de projeto naquele ponto espec√≠fico. 

O uso desta t√©cnica trouxe benef√≠cios adicionais ao que foi identificado no estudo de caso anterior, com a redu√ß√£o do n√∫mero de interven√ß√µes de manuten√ß√µes (coleta online) e garantir que o intervalo P-F seja mais bem entendido com a an√°lise dos dados de temperatura.

Adicionalmente, a falta de par√¢metros claros de monitoramento aliado ao consider√°vel n√∫mero de pequenos componentes que podem ser cobertos por este modelo de monitoramento, a abordagem realizada neste estudo pode ser indicada para viabilizar tais t√©cnicas de monitoramento para garantir a confiabilidade do sistema, aumentar a precis√£o na tomada de decis√£o das manuten√ß√µes e atualiza√ß√µes das m√°quinas e equipamentos.



**7.	Refer√™ncias Bibliogr√°ficas**

Aguirre-Jofr√©, H. Eyre, M.Valerio, S. Vogt, D 2021. Low-cost internet of things (IoT) for monitoring and optimising mining small-scale trucks and surface mining shovels. Camborne School of Mines, University of Exeter, Exeter, United Kingdom and ndependent Consultant, Dataquest 131: 103918. 

Aileen Nielsen 2021. An√°lise pr√°tica de s√©ries temporais: predi√ß√£o com estat√≠stica e aprendizado de m√°quina. Alta Books: Rio de Janeiro

Artur Skoczylasa,Pawe≈Ç Stefaniaka, Wies≈Çawa Gryncewiczb, Artur Rotb 2023. The Concept of an Intelligent Decision Support System for Ore Transportation in Underground Mine. 27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems 2023: 922‚Äì931. 

Aur√©lien G√©ron 2021. Maos √† Obra: Aprendizagem de M√°quina com Scikit-Learn, Keras e TensrFlow - 2nd edi√ß√£o atualizada com TensorFlow2. O'Reilly Media, Inc.: Rio de Janeiro.

Daniel Schmidt, Karsten Berns 2013. Climbing robots for maintenance and inspections of vertical structures - A survey of design aspects and technologies. Robotics and Autonomous Systems 61: 1288-1305. 

F√ÅVERO, Luiz Paulo Lopes e BELFIORE, Patr√≠cia Prado 2024. Manual de An√°lise de Dados ‚Äì Estat√≠stica e Machine Learning com Excel¬Æ, SPSS¬Æ, Stata¬Æ, R¬Æ e Python¬Æ. GEN LTC: Rio de janeiro

Ferreira, B., Seruffo, M., & Pires, Y.  2022. Planejamento e constru√ß√£o de um prot√≥tipo de aplicativo mobilem para visualiza√ß√£o de dados de sistema de monitoramento de m√°quinas e equipamentos. Revista Principia - Divulga√ß√£o Cient√≠fica e Tecnol√≥gica do IFPB 59(3): 947-966. 

Gbadamosi, Abdul-Quayyum & Oyedele, Lukumon & Davila Delgado, Manuel & Kusimo, Habeeb & Akanbi, Lukman & Olawale, Oladimeji & Muhammed -Yakubu, Naimah 2021. IoT for predictive assets monitoring and maintenance: An implementation strategy for the UK rail industry. Automation in Construction 122: 103486. 10.1016/j.autcon.2020.103486.

Jo√£o Pedro Dias, Andr√© Restivo, Hugo Sereno Ferreira 2022. Designing and constructing internet-of-Things systems: An overview of the ecosystem. Internet of Things. journal homepage: www.elsevier.com/locate/io 19: 100529. 

Manh-Kien Tran, Satyam Panchal, Vedang Chauhan, Niku Brahmbhatt, Anosh Mevawalla, Roydon Fraser, Michael Fowler 2021. Python-based scikit-learn machine learning models forthermal and electrical performance prediction of high-capacity lithium-ion battery. Int J Energy Res.2022 46: 786‚Äì794. 

Nascimento, E. dos S., Maroli, K. R., Dias, G. C. M., & Bov√©rio, M. A.  2020. GEST√ÉO DE MANUTEN√á√ÉO INDUSTRIAL: eletrifica√ß√£o de acionamento de terno de moenda. SITEFA 3(1): 180‚Äì191.

Pedro A. Morettin, Cl√©lia M. C. Toloi 2020. An√°lise de Series Temporais Modelos multivariados e n√£o lineares. Edgard Blucher : S√£o Paulo, SP.

scikit-learn.org scikit-learn. 2024 scikit-learn: Machine Learning in Python: https://scikit-learn.org/stable/

Yingming Tian, Fan Gao and Peng Wu2 1992. Intelligent Diagnosis of Equipment Health Based on IOT and Operation Large Data Analysis. Journal of Physics: Conference Series : 1742-6596.
